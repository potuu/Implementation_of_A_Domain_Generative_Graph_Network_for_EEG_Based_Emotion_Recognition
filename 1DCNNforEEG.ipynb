{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/potuu/Implementation_of_A_Domain_Generative_Graph_Network_for_EEG_Based_Emotion_Recognition/blob/main/1DCNNforEEG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREPROCESSING"
      ],
      "metadata": {
        "id": "vuA_P_i2iuHE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cgcie5DzoObi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-U12Nda9xoa",
        "outputId": "4a7d3b2c-e404-43a9-ead5-85b3d0c9399b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_eeg_directory(directory_path):\n",
        "    \"\"\"\n",
        "    Processes all subject and experiment files in a directory, groups data by `user_id`,\n",
        "    adds a unique ID based on the file name, and combines all grouped data into a single DataFrame.\n",
        "\n",
        "    Args:\n",
        "    - directory_path (str): Path to the directory containing EEG data files.\n",
        "\n",
        "    Returns:\n",
        "    - combined_data (pd.DataFrame): A single DataFrame containing all grouped data.\n",
        "    \"\"\"\n",
        "    grouped_data = []\n",
        "\n",
        "    # List all files in the directory\n",
        "    file_list = [f for f in os.listdir(directory_path) if f.endswith('.csv')]\n",
        "\n",
        "    # Loop through each file\n",
        "    for file_name in file_list:\n",
        "        file_path = os.path.join(directory_path, file_name)\n",
        "\n",
        "        # Read the CSV file into a DataFrame\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Check if `user_id` column exists\n",
        "        if 'user_id' in df.columns:\n",
        "            # Add a column to indicate the source file (unique ID for rows from this file)\n",
        "            df['source_file'] = os.path.splitext(file_name)[0]  # File name without extension\n",
        "\n",
        "            # Group by `user_id` and aggregate data into lists\n",
        "            grouped = df.groupby('user_id').agg(list).reset_index()\n",
        "\n",
        "            # Preserve the unique ID (source file) in the grouped data\n",
        "            grouped['source_file'] = os.path.splitext(file_name)[0]\n",
        "\n",
        "            # Append the grouped data to the list\n",
        "            grouped_data.append(grouped)\n",
        "        else:\n",
        "            print(f\"'user_id' column not found in file: {file_name}\")\n",
        "\n",
        "    # Combine all grouped data into a single DataFrame\n",
        "    if grouped_data:\n",
        "        combined_data = pd.concat(grouped_data, ignore_index=True)\n",
        "        print(\"All files have been grouped by `user_id` and combined successfully.\")\n",
        "    else:\n",
        "        combined_data = pd.DataFrame()\n",
        "        print(\"No data was processed or combined.\")\n",
        "\n",
        "    return combined_data\n",
        "\n",
        "\n",
        "# Example usage\n",
        "directory_path = \"/content/drive/MyDrive/eeg_database_kou/data_trail_csv\"  # Replace with your actual directory path\n",
        "combined_eeg_data = process_eeg_directory(directory_path)\n",
        "\n",
        "# Save the combined data to a CSV file (optional)\n",
        "combined_eeg_data.to_csv(\"grouped_combined_eeg_data.csv\", index=False)\n",
        "\n",
        "# Display a preview of the combined data\n",
        "print(\"Combined EEG Data:\")\n",
        "print(combined_eeg_data.head())"
      ],
      "metadata": {
        "id": "vN_H90M1oUbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a40435fb-1070-4d71-c914-2e5355b2a002"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All files have been grouped by `user_id` and combined successfully.\n",
            "Combined EEG Data:\n",
            "                                user_id  \\\n",
            "0  06f49575-a0ee-46fd-8d0d-4133886d62a5   \n",
            "1  4737537c-0a5d-46e2-9c1f-9872520872c4   \n",
            "2  4737537c-0a5d-46e2-9c1f-9872520872c4   \n",
            "3  06f49575-a0ee-46fd-8d0d-4133886d62a5   \n",
            "4  06f49575-a0ee-46fd-8d0d-4133886d62a5   \n",
            "\n",
            "                                           Timestamp  \\\n",
            "0  [10:51:23 AM, 10:51:23 AM, 10:51:23 AM, 10:51:...   \n",
            "1  [10:39:08 AM, 10:39:08 AM, 10:39:08 AM, 10:39:...   \n",
            "2  [10:40:17 AM, 10:40:17 AM, 10:40:17 AM, 10:40:...   \n",
            "3  [10:54:24 AM, 10:54:24 AM, 10:54:24 AM, 10:54:...   \n",
            "4  [10:54:59 AM, 10:54:59 AM, 10:54:59 AM, 10:54:...   \n",
            "\n",
            "                                             EEG.AF3  \\\n",
            "0  [3891.281982, 3895.384521, 3906.153809, 3900.0...   \n",
            "1  [4017.435791, 4020.512939, 4015.384521, 4005.1...   \n",
            "2  [4081.538574, 4083.589844, 4080.512939, 4074.3...   \n",
            "3  [3981.025635, 3972.820557, 3965.641113, 3968.2...   \n",
            "4  [3951.281982, 3953.846191, 3957.435791, 3954.8...   \n",
            "\n",
            "                                              EEG.F7  \\\n",
            "0  [4160.0, 4166.666504, 4174.871582, 4169.230957...   \n",
            "1  [4245.128418, 4254.358887, 4250.769043, 4239.4...   \n",
            "2  [4361.025879, 4365.641113, 4358.461426, 4346.1...   \n",
            "3  [4150.769043, 4145.641113, 4137.94873, 4145.64...   \n",
            "4  [4236.922852, 4243.077148, 4245.128418, 4238.4...   \n",
            "\n",
            "                                              EEG.F3  \\\n",
            "0  [3673.333252, 3671.281982, 3678.461426, 3675.3...   \n",
            "1  [3796.923096, 3808.718018, 3805.128174, 3784.6...   \n",
            "2  [3842.564209, 3847.179443, 3842.05127, 3829.23...   \n",
            "3  [3720.512939, 3716.923096, 3713.846191, 3714.3...   \n",
            "4  [3740.512939, 3736.410156, 3736.410156, 3738.9...   \n",
            "\n",
            "                                             EEG.FC5  \\\n",
            "0  [4122.05127, 4119.487305, 4125.641113, 4128.20...   \n",
            "1  [4116.410156, 4128.717773, 4116.922852, 4100.5...   \n",
            "2  [4176.922852, 4180.512695, 4173.333496, 4161.0...   \n",
            "3  [4148.205078, 4145.128418, 4141.538574, 4143.5...   \n",
            "4  [4126.666504, 4135.897461, 4138.974121, 4133.8...   \n",
            "\n",
            "                                              EEG.T7  \\\n",
            "0  [3999.487061, 4003.589844, 4011.281982, 4011.2...   \n",
            "1  [4105.128418, 4105.128418, 4103.589844, 4106.1...   \n",
            "2  [4099.487305, 4107.179688, 4109.743652, 4102.5...   \n",
            "3  [4052.307617, 4047.179443, 4043.589844, 4052.3...   \n",
            "4  [4058.461426, 4061.025635, 4065.128174, 4063.0...   \n",
            "\n",
            "                                              EEG.P7  \\\n",
            "0  [4099.487305, 4104.102539, 4113.846191, 4117.4...   \n",
            "1  [4184.102539, 4177.436035, 4180.512695, 4183.0...   \n",
            "2  [4176.922852, 4180.0, 4180.512695, 4176.922852...   \n",
            "3  [4072.820557, 4071.794922, 4073.846191, 4080.0...   \n",
            "4  [4142.05127, 4142.563965, 4146.666504, 4151.28...   \n",
            "\n",
            "                                              EEG.O1  \\\n",
            "0  [4008.718018, 4016.923096, 4035.897461, 4043.0...   \n",
            "1  [4158.974121, 4158.461426, 4167.692383, 4162.5...   \n",
            "2  [4160.0, 4162.563965, 4166.153809, 4168.205078...   \n",
            "3  [4069.743652, 4068.718018, 4068.718018, 4076.4...   \n",
            "4  [4100.512695, 4101.025879, 4104.102539, 4104.6...   \n",
            "\n",
            "                                              EEG.O2  \\\n",
            "0  [3998.461426, 4001.538574, 4007.692383, 4006.6...   \n",
            "1  [4118.974121, 4118.461426, 4126.666504, 4125.6...   \n",
            "2  [4380.512695, 4376.410156, 4377.436035, 4381.5...   \n",
            "3  [4026.666748, 4024.615479, 4024.102539, 4029.2...   \n",
            "4  [4036.923096, 4037.94873, 4041.025635, 4045.12...   \n",
            "\n",
            "                                              EEG.P8  \\\n",
            "0  [3801.538574, 3800.0, 3804.615479, 3804.102539...   \n",
            "1  [3928.718018, 3929.743652, 3943.076904, 3950.7...   \n",
            "2  [3959.487061, 3957.435791, 3960.512939, 3965.1...   \n",
            "3  [3814.871826, 3817.435791, 3820.0, 3823.589844...   \n",
            "4  [3855.897461, 3854.871826, 3858.974365, 3858.4...   \n",
            "\n",
            "                                              EEG.T8  \\\n",
            "0  [4606.666504, 4599.487305, 4601.025879, 4607.1...   \n",
            "1  [4600.512695, 4610.256348, 4621.025879, 4620.0...   \n",
            "2  [4608.717773, 4609.230957, 4608.717773, 4603.5...   \n",
            "3  [4323.589844, 4318.974121, 4317.436035, 4324.1...   \n",
            "4  [4626.666504, 4622.563965, 4644.102539, 4664.6...   \n",
            "\n",
            "                                             EEG.FC6  \\\n",
            "0  [4384.102539, 4385.641113, 4396.922852, 4394.3...   \n",
            "1  [4431.794922, 4440.512695, 4447.179688, 4442.5...   \n",
            "2  [4464.615234, 4472.820313, 4471.282227, 4462.0...   \n",
            "3  [4453.846191, 4444.102539, 4439.487305, 4448.2...   \n",
            "4  [4429.743652, 4435.897461, 4443.589844, 4438.9...   \n",
            "\n",
            "                                              EEG.F4  \\\n",
            "0  [4398.974121, 4403.077148, 4407.692383, 4402.5...   \n",
            "1  [4568.205078, 4572.307617, 4571.794922, 4558.4...   \n",
            "2  [4586.153809, 4586.153809, 4587.692383, 4587.6...   \n",
            "3  [4443.077148, 4438.461426, 4438.974121, 4442.5...   \n",
            "4  [4486.153809, 4484.102539, 4492.307617, 4497.4...   \n",
            "\n",
            "                                              EEG.F8  \\\n",
            "0  [4117.94873, 4114.871582, 4122.05127, 4124.102...   \n",
            "1  [4072.307617, 4075.384521, 4089.743652, 4088.7...   \n",
            "2  [4109.743652, 4110.256348, 4110.256348, 4107.6...   \n",
            "3  [4177.436035, 4167.179688, 4161.538574, 4165.6...   \n",
            "4  [4130.256348, 4135.384766, 4138.461426, 4138.4...   \n",
            "\n",
            "                                             EEG.AF4 source_file  \n",
            "0  [4429.230957, 4434.871582, 4440.0, 4429.743652...         4_6  \n",
            "1  [4601.538574, 4605.128418, 4603.589844, 4591.7...       40_18  \n",
            "2  [4681.025879, 4685.128418, 4685.128418, 4676.9...       40_20  \n",
            "3  [4564.102539, 4557.94873, 4557.436035, 4562.56...        4_11  \n",
            "4  [4498.461426, 4500.0, 4504.615234, 4504.102539...        4_12  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the DataFrame by `source_file` with proper numerical order\n",
        "combined_eeg_data['source_file'] = combined_eeg_data['source_file'].str.split('_').map(lambda x: (int(x[0]), int(x[1])))\n",
        "combined_eeg_data = combined_eeg_data.sort_values(by='source_file').reset_index(drop=True)\n",
        "\n",
        "# Display sorted `source_file` column\n",
        "print(combined_eeg_data['source_file'].head())"
      ],
      "metadata": {
        "id": "yWAqDGdToiIa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22726bd3-9d78-4e4f-a69f-d986c66a4fc2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    (1, 1)\n",
            "1    (1, 2)\n",
            "2    (1, 3)\n",
            "3    (1, 4)\n",
            "4    (1, 5)\n",
            "Name: source_file, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_data_path = \"/content/drive/MyDrive/eeg_database_kou/label_processed_data.csv\"\n",
        "labels_data = pd.read_csv(labels_data_path)\n",
        "split_columns = [\"user_id\", \"trial\", \"start_date\", \"finish_date\", \"duration\", \"val\", \"aro\", \"dom\"]\n",
        "processed_labels_data = labels_data.iloc[:, 0].str.split(\";\", expand=True)\n",
        "processed_labels_data.columns = split_columns\n",
        "\n",
        "# Inspect the transformed data\n",
        "print(\"Labels Preview:\")\n",
        "print(processed_labels_data.head())\n",
        "\n",
        "# Check for missing values in label data\n",
        "print(\"\\nMissing Values in Label Data:\")\n",
        "print(processed_labels_data.isnull().sum())"
      ],
      "metadata": {
        "id": "jIRNvIDSolfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "935e7987-3f57-4ec9-813d-5e621ab3cc9c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels Preview:\n",
            "                                user_id trial                  start_date  \\\n",
            "0  7a4efc4f-6def-4ba3-a56d-672aec0fe324     1  2023-10-11 12:45:06.863000   \n",
            "1  7a4efc4f-6def-4ba3-a56d-672aec0fe324     2  2023-10-11 12:45:41.053000   \n",
            "2  7a4efc4f-6def-4ba3-a56d-672aec0fe324     3  2023-10-11 12:46:15.225000   \n",
            "3  7a4efc4f-6def-4ba3-a56d-672aec0fe324     4  2023-10-11 12:46:49.414000   \n",
            "4  7a4efc4f-6def-4ba3-a56d-672aec0fe324     5  2023-10-11 12:47:33.596000   \n",
            "\n",
            "                  finish_date duration val aro dom  \n",
            "0  2023-10-11 12:45:35.888000       29   1   0   1  \n",
            "1  2023-10-11 12:46:10.055000       29   0   1   1  \n",
            "2  2023-10-11 12:46:44.240000       29   1   1   0  \n",
            "3  2023-10-11 12:47:18.427000       29   0   1   1  \n",
            "4  2023-10-11 12:48:02.605000       29   1   0   0  \n",
            "\n",
            "Missing Values in Label Data:\n",
            "user_id        0\n",
            "trial          0\n",
            "start_date     0\n",
            "finish_date    0\n",
            "duration       0\n",
            "val            0\n",
            "aro            0\n",
            "dom            0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Add the `source_file` column to processed_labels_data\n",
        "processed_labels_data['source_file'] = processed_labels_data.apply(\n",
        "    lambda row: (math.ceil((row.name + 1) / 20), int(row['trial'])),  # 20 trials per subject\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Inspect the updated DataFrame\n",
        "print(\"Processed Labels with Source File:\")\n",
        "print(processed_labels_data.tail())\n"
      ],
      "metadata": {
        "id": "wpZtAjIZooGF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8552a1ca-9d6b-4206-9093-075a458f7730"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Labels with Source File:\n",
            "                                  user_id trial                  start_date  \\\n",
            "795  4737537c-0a5d-46e2-9c1f-9872520872c4    16  2023-12-14 10:37:49.814000   \n",
            "796  4737537c-0a5d-46e2-9c1f-9872520872c4    17  2023-12-14 10:38:34.042000   \n",
            "797  4737537c-0a5d-46e2-9c1f-9872520872c4    18  2023-12-14 10:39:08.306000   \n",
            "798  4737537c-0a5d-46e2-9c1f-9872520872c4    19  2023-12-14 10:39:42.525000   \n",
            "799  4737537c-0a5d-46e2-9c1f-9872520872c4    20  2023-12-14 10:40:16.724000   \n",
            "\n",
            "                    finish_date duration val aro dom source_file  \n",
            "795  2023-12-14 10:38:18.829000       29   0   1   1    (40, 16)  \n",
            "796  2023-12-14 10:39:03.078000       29   1   1   1    (40, 17)  \n",
            "797  2023-12-14 10:39:37.327000       29   0   1   1    (40, 18)  \n",
            "798  2023-12-14 10:40:11.539000       29   1   1   1    (40, 19)  \n",
            "799  2023-12-14 10:40:45.751000       29   0   1   1    (40, 20)  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Bandpass Filter Function\n",
        "def bandpass_filter(data, lowcut=1.0, highcut=50.0, fs=128.0, order=4):\n",
        "    \"\"\"\n",
        "    Apply a bandpass filter to EEG data.\n",
        "\n",
        "    Args:\n",
        "    - data (ndarray): EEG data (timesteps x channels).\n",
        "    - lowcut (float): Low cutoff frequency in Hz.\n",
        "    - highcut (float): High cutoff frequency in Hz.\n",
        "    - fs (float): Sampling frequency in Hz.\n",
        "    - order (int): Filter order.\n",
        "\n",
        "    Returns:\n",
        "    - filtered_data (ndarray): Bandpass filtered EEG data.\n",
        "    \"\"\"\n",
        "    nyquist = 0.5 * fs\n",
        "    low = lowcut / nyquist\n",
        "    high = highcut / nyquist\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    filtered_data = filtfilt(b, a, data, axis=0)\n",
        "    return filtered_data\n",
        "\n",
        "# Preprocess EEG Data without Labels\n",
        "def preprocess_eeg_data(df, target_length=3712, lowcut=1.0, highcut=50.0, fs=128.0):\n",
        "    \"\"\"\n",
        "    Preprocess EEG data by applying a bandpass filter and fixing the length.\n",
        "\n",
        "    Args:\n",
        "    - df (DataFrame): Raw EEG data DataFrame (columns are EEG channels).\n",
        "    - target_length (int): Fixed length for time-series data.\n",
        "    - lowcut (float): Low cutoff frequency for the filter.\n",
        "    - highcut (float): High cutoff frequency for the filter.\n",
        "    - fs (float): Sampling frequency.\n",
        "\n",
        "    Returns:\n",
        "    - data (ndarray): Preprocessed EEG data of shape (samples, timesteps, channels).\n",
        "    \"\"\"\n",
        "    n_samples = len(df)\n",
        "    n_channels = len(df.columns)  # Assuming all columns are EEG channels\n",
        "    data = np.zeros((n_samples, target_length, n_channels))\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        for j in range(n_channels):\n",
        "            channel_data = df.iloc[i, j]\n",
        "            if isinstance(channel_data, str):\n",
        "                channel_data = eval(channel_data)  # Convert string to list\n",
        "\n",
        "            # Apply bandpass filter\n",
        "            channel_data = bandpass_filter(np.array(channel_data), lowcut, highcut, fs)\n",
        "\n",
        "            # Adjust length\n",
        "            if len(channel_data) < target_length:\n",
        "                channel_data = np.pad(channel_data, (0, target_length - len(channel_data)), 'constant')\n",
        "            else:\n",
        "                channel_data = channel_data[:target_length]\n",
        "\n",
        "            data[i, :, j] = channel_data\n",
        "\n",
        "    return data\n",
        "\n",
        "# Min-Max Scaling\n",
        "def apply_min_max_scaling(data):\n",
        "    \"\"\"\n",
        "    Apply Min-Max scaling to EEG data.\n",
        "\n",
        "    Args:\n",
        "    - data (ndarray): EEG data (samples x timesteps x channels).\n",
        "\n",
        "    Returns:\n",
        "    - scaled_data (ndarray): Scaled EEG data.\n",
        "    \"\"\"\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    n_samples, n_timesteps, n_channels = data.shape\n",
        "    scaled_data = np.zeros_like(data)\n",
        "\n",
        "    # Scale each channel independently\n",
        "    for ch in range(n_channels):\n",
        "        reshaped_data = data[:, :, ch].reshape(-1, 1)  # Flatten for scaling\n",
        "        scaled_channel = scaler.fit_transform(reshaped_data).reshape(n_samples, n_timesteps)\n",
        "        scaled_data[:, :, ch] = scaled_channel\n",
        "\n",
        "    return scaled_data"
      ],
      "metadata": {
        "id": "0zcQYTE3ouro"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure 'source_file' is in tuple format for both DataFrames\n",
        "combined_eeg_data['source_file'] = combined_eeg_data['source_file'].apply(\n",
        "    lambda x: eval(x) if isinstance(x, str) else x\n",
        ")\n",
        "processed_labels_data['source_file'] = processed_labels_data['source_file'].apply(\n",
        "    lambda x: eval(x) if isinstance(x, str) else x\n",
        ")\n",
        "\n",
        "# Merge combined_eeg_data with processed_labels_data based on 'source_file'\n",
        "merged_data = combined_eeg_data.merge(\n",
        "    processed_labels_data[['source_file', 'aro', 'val']],\n",
        "    on='source_file',\n",
        "    how='left'  # Use 'left' join to keep all rows from combined_eeg_data\n",
        ")\n",
        "\n",
        "# Inspect the resulting DataFrame\n",
        "print(\"Merged Data (with Labels):\")\n",
        "print(merged_data.head())\n",
        "\n",
        "# Save the merged DataFrame to a new CSV file (optional)\n",
        "#merged_data.to_csv(\"merged_eeg_with_labels.csv\", index=False)"
      ],
      "metadata": {
        "id": "tL7p665Nox5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8936a74-bdc6-4b43-cd51-82c24d7e78f8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged Data (with Labels):\n",
            "                                user_id  \\\n",
            "0  7a4efc4f-6def-4ba3-a56d-672aec0fe324   \n",
            "1  7a4efc4f-6def-4ba3-a56d-672aec0fe324   \n",
            "2  7a4efc4f-6def-4ba3-a56d-672aec0fe324   \n",
            "3  7a4efc4f-6def-4ba3-a56d-672aec0fe324   \n",
            "4  7a4efc4f-6def-4ba3-a56d-672aec0fe324   \n",
            "\n",
            "                                           Timestamp  \\\n",
            "0  [12:45:07 PM, 12:45:07 PM, 12:45:07 PM, 12:45:...   \n",
            "1  [12:45:41 PM, 12:45:41 PM, 12:45:41 PM, 12:45:...   \n",
            "2  [12:46:15 PM, 12:46:15 PM, 12:46:15 PM, 12:46:...   \n",
            "3  [12:46:49 PM, 12:46:49 PM, 12:46:49 PM, 12:46:...   \n",
            "4  [12:47:34 PM, 12:47:34 PM, 12:47:34 PM, 12:47:...   \n",
            "\n",
            "                                             EEG.AF3  \\\n",
            "0  [4018.461426, 4014.871826, 4011.794922, 4010.2...   \n",
            "1  [3984.615479, 3990.256348, 3988.205078, 3980.5...   \n",
            "2  [3985.641113, 3987.692383, 3985.641113, 3985.6...   \n",
            "3  [4014.358887, 4011.794922, 4015.897461, 4015.3...   \n",
            "4  [3727.692383, 3735.384521, 3740.512939, 3735.3...   \n",
            "\n",
            "                                              EEG.F7  \\\n",
            "0  [4269.230957, 4261.538574, 4252.820313, 4247.1...   \n",
            "1  [4274.358887, 4278.974121, 4270.769043, 4263.5...   \n",
            "2  [4320.512695, 4320.0, 4327.692383, 4338.974121...   \n",
            "3  [4216.410156, 4220.0, 4234.871582, 4243.589844...   \n",
            "4  [4250.769043, 4256.922852, 4252.820313, 4249.2...   \n",
            "\n",
            "                                              EEG.F3  \\\n",
            "0  [3793.846191, 3794.358887, 3788.205078, 3785.1...   \n",
            "1  [3747.692383, 3749.230713, 3746.666748, 3740.5...   \n",
            "2  [3793.333252, 3796.923096, 3794.871826, 3794.8...   \n",
            "3  [3769.230713, 3772.307617, 3775.897461, 3771.7...   \n",
            "4  [3791.281982, 3800.0, 3805.641113, 3796.410156...   \n",
            "\n",
            "                                             EEG.FC5  \\\n",
            "0  [4104.615234, 4103.589844, 4102.563965, 4101.5...   \n",
            "1  [4115.384766, 4115.897461, 4114.358887, 4112.3...   \n",
            "2  [4109.743652, 4111.282227, 4107.179688, 4108.7...   \n",
            "3  [4129.230957, 4129.230957, 4132.820313, 4132.8...   \n",
            "4  [4119.487305, 4115.897461, 4113.846191, 4118.9...   \n",
            "\n",
            "                                              EEG.T7  \\\n",
            "0  [4106.153809, 4102.05127, 4101.538574, 4102.56...   \n",
            "1  [4078.461426, 4075.897461, 4073.333252, 4075.8...   \n",
            "2  [4076.410156, 4071.794922, 4066.153809, 4068.7...   \n",
            "3  [4092.307617, 4097.94873, 4101.538574, 4098.46...   \n",
            "4  [4082.05127, 4084.615479, 4085.641113, 4087.17...   \n",
            "\n",
            "                                              EEG.P7  \\\n",
            "0  [4095.384521, 4093.846191, 4093.333252, 4091.2...   \n",
            "1  [4151.794922, 4155.384766, 4155.384766, 4155.3...   \n",
            "2  [4122.563965, 4124.102539, 4116.410156, 4115.3...   \n",
            "3  [4120.512695, 4125.641113, 4140.0, 4140.0, 413...   \n",
            "4  [4150.256348, 4152.820313, 4155.384766, 4155.8...   \n",
            "\n",
            "                                              EEG.O1  \\\n",
            "0  [4060.512939, 4066.153809, 4063.076904, 4061.0...   \n",
            "1  [4024.102539, 4032.820557, 4033.846191, 4030.7...   \n",
            "2  [4010.256348, 4021.025635, 4018.461426, 4019.4...   \n",
            "3  [4154.358887, 4152.307617, 4164.102539, 4163.5...   \n",
            "4  [4177.436035, 4180.0, 4182.563965, 4186.153809...   \n",
            "\n",
            "                                              EEG.O2  \\\n",
            "0  [4052.307617, 4056.410156, 4068.205078, 4078.4...   \n",
            "1  [4081.025635, 4090.256348, 4090.769287, 4089.7...   \n",
            "2  [4023.589844, 4032.307617, 4029.230713, 4027.1...   \n",
            "3  [4055.384521, 4048.205078, 4051.281982, 4050.7...   \n",
            "4  [4072.820557, 4076.923096, 4075.384521, 4072.8...   \n",
            "\n",
            "                                              EEG.P8  \\\n",
            "0  [3903.589844, 3906.153809, 3914.871826, 3932.3...   \n",
            "1  [3986.153809, 3991.281982, 3991.281982, 3978.4...   \n",
            "2  [3890.769287, 3900.512939, 3892.307617, 3890.2...   \n",
            "3  [3947.692383, 3943.076904, 3951.794922, 3951.2...   \n",
            "4  [3934.358887, 3947.692383, 3946.153809, 3939.4...   \n",
            "\n",
            "                                              EEG.T8  \\\n",
            "0  [4510.256348, 4512.307617, 4526.153809, 4533.3...   \n",
            "1  [4533.333496, 4540.512695, 4558.461426, 4558.4...   \n",
            "2  [4539.487305, 4545.641113, 4537.94873, 4530.76...   \n",
            "3  [4518.974121, 4508.717773, 4513.846191, 4516.9...   \n",
            "4  [4572.307617, 4568.205078, 4566.666504, 4581.5...   \n",
            "\n",
            "                                             EEG.FC6  \\\n",
            "0  [4497.436035, 4454.871582, 4456.922852, 4505.1...   \n",
            "1  [4477.94873, 4486.666504, 4486.153809, 4477.94...   \n",
            "2  [4504.615234, 4506.666504, 4497.94873, 4495.38...   \n",
            "3  [4457.94873, 4455.384766, 4464.102539, 4466.15...   \n",
            "4  [4444.102539, 4448.717773, 4453.333496, 4456.4...   \n",
            "\n",
            "                                              EEG.F4  \\\n",
            "0  [4372.820313, 4371.282227, 4365.641113, 4367.1...   \n",
            "1  [4586.153809, 4589.230957, 4590.769043, 4589.7...   \n",
            "2  [4569.230957, 4573.333496, 4563.077148, 4561.5...   \n",
            "3  [4506.153809, 4507.692383, 4514.871582, 4513.3...   \n",
            "4  [4548.205078, 4552.307617, 4556.922852, 4556.9...   \n",
            "\n",
            "                                              EEG.F8  \\\n",
            "0  [4113.333496, 4106.666504, 4104.615234, 4111.7...   \n",
            "1  [4062.564209, 4072.307617, 4069.743652, 4063.0...   \n",
            "2  [4026.666748, 4009.743652, 3996.923096, 3985.6...   \n",
            "3  [4121.538574, 4121.025879, 4125.641113, 4125.6...   \n",
            "4  [4138.461426, 4137.94873, 4140.512695, 4150.25...   \n",
            "\n",
            "                                             EEG.AF4 source_file aro val  \n",
            "0  [4636.410156, 4592.307617, 4599.487305, 4643.5...      (1, 1)   0   1  \n",
            "1  [4658.974121, 4671.794922, 4672.820313, 4665.1...      (1, 2)   1   0  \n",
            "2  [4597.94873, 4599.487305, 4585.641113, 4581.53...      (1, 3)   1   1  \n",
            "3  [4617.94873, 4613.846191, 4625.128418, 4626.15...      (1, 4)   1   0  \n",
            "4  [4593.846191, 4598.461426, 4612.820313, 4615.3...      (1, 5)   0   1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_user_ids = len(merged_data)\n",
        "\n",
        "print(f\"Number of samples: {num_user_ids}\")"
      ],
      "metadata": {
        "id": "IHDChFCho1Af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "024f5e30-e74e-4475-a318-c647f7647ea4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data.shape"
      ],
      "metadata": {
        "id": "1oEMxHzlOc7L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d9be43-f208-45e1-f896-b3ee927c0a44"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EEG ile başlayan sütunları seçelim\n",
        "eeg_columns = [col for col in merged_data.columns if col.startswith('EEG.')]\n",
        "\n",
        "# EEG sütunlarındaki array'lerde kaç veri olduğunu yazdıralım\n",
        "for col in eeg_columns:\n",
        "    # Her bir sütundaki array'in boyutunu yazdırıyoruz\n",
        "    print(f\"{col}: {len(merged_data[col].iloc[0])} verisi var.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBqA14upBGVt",
        "outputId": "9ae2eaff-e200-46d1-daee-e34ed0093ab1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EEG.AF3: 3708 verisi var.\n",
            "EEG.F7: 3708 verisi var.\n",
            "EEG.F3: 3708 verisi var.\n",
            "EEG.FC5: 3708 verisi var.\n",
            "EEG.T7: 3708 verisi var.\n",
            "EEG.P7: 3708 verisi var.\n",
            "EEG.O1: 3708 verisi var.\n",
            "EEG.O2: 3708 verisi var.\n",
            "EEG.P8: 3708 verisi var.\n",
            "EEG.T8: 3708 verisi var.\n",
            "EEG.FC6: 3708 verisi var.\n",
            "EEG.F4: 3708 verisi var.\n",
            "EEG.F8: 3708 verisi var.\n",
            "EEG.AF4: 3708 verisi var.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# satır yapısını gözlemlemek adına rastgele 346. satırdaki verilere ulaşmak için\n",
        "print(merged_data.iloc[345])\n"
      ],
      "metadata": {
        "id": "DmGqvBH7AY-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8143b557-a3a9-4b90-db77-ae00a24fbb05"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_id                     9bbf02ef-b2a5-4956-8654-5de9eaa126c4\n",
            "Timestamp      [02:59:30 PM, 02:59:30 PM, 02:59:30 PM, 02:59:...\n",
            "EEG.AF3        [3986.153809, 3993.846191, 3996.923096, 3994.8...\n",
            "EEG.F7         [4183.077148, 4192.820313, 4196.410156, 4187.1...\n",
            "EEG.F3         [3783.589844, 3784.615479, 3785.641113, 3783.0...\n",
            "EEG.FC5        [4107.692383, 4108.205078, 4121.538574, 4118.4...\n",
            "EEG.T7         [4095.384521, 4093.846191, 4091.281982, 4091.7...\n",
            "EEG.P7         [4158.461426, 4154.871582, 4152.820313, 4154.3...\n",
            "EEG.O1         [4173.846191, 4169.743652, 4169.230957, 4170.2...\n",
            "EEG.O2         [4122.05127, 4122.05127, 4113.846191, 4111.282...\n",
            "EEG.P8         [3913.846191, 3920.512939, 3914.871826, 3907.1...\n",
            "EEG.T8         [4504.615234, 4514.871582, 4515.897461, 4509.7...\n",
            "EEG.FC6        [4480.512695, 4491.282227, 4494.358887, 4489.2...\n",
            "EEG.F4         [4554.871582, 4562.563965, 4567.179688, 4562.5...\n",
            "EEG.F8         [4076.410156, 4091.794922, 4097.94873, 4092.30...\n",
            "EEG.AF4        [4523.589844, 4535.384766, 4540.512695, 4536.9...\n",
            "source_file                                              (18, 6)\n",
            "aro                                                            0\n",
            "val                                                            0\n",
            "Name: 345, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# İlk satırdaki EEG.F8 değerini almak\n",
        "row_index = 0  # Hangi satırı kontrol etmek istiyorsanız o indeksi belirtin\n",
        "f8_values = merged_data.loc[row_index, \"EEG.F8\"]\n",
        "\n",
        "print(f8_values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5oQ4BavSypl",
        "outputId": "d746f0a0-7801-4eac-8c78-0882c78e83aa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4113.333496, 4106.666504, 4104.615234, 4111.794922, 4117.436035, 4116.922852, 4135.384766, 4177.436035, 4191.794922, 4173.846191, 4165.641113, 4172.307617, 4170.769043, 4160.512695, 4151.282227, 4134.358887, 4115.897461, 4114.358887, 4120.512695, 4110.769043, 4101.025879, 4108.717773, 4116.922852, 4114.871582, 4109.230957, 4104.102539, 4104.102539, 4106.153809, 4108.205078, 4114.358887, 4120.512695, 4121.025879, 4120.0, 4121.025879, 4117.94873, 4110.256348, 4106.666504, 4110.769043, 4110.256348, 4109.743652, 4115.384766, 4114.871582, 4105.641113, 4103.589844, 4108.205078, 4107.179688, 4105.641113, 4106.666504, 4105.128418, 4103.589844, 4103.589844, 4105.641113, 4108.717773, 4112.820313, 4110.769043, 4110.256348, 4112.307617, 4111.794922, 4110.769043, 4112.307617, 4114.358887, 4113.333496, 4111.282227, 4107.179688, 4102.563965, 4106.666504, 4123.589844, 4141.025879, 4148.205078, 4150.769043, 4155.897461, 4153.846191, 4140.512695, 4137.94873, 4149.743652, 4148.205078, 4142.563965, 4154.871582, 4161.538574, 4153.846191, 4154.358887, 4154.358887, 4148.717773, 4155.897461, 4165.128418, 4157.94873, 4149.230957, 4152.820313, 4162.563965, 4169.743652, 4163.077148, 4151.282227, 4149.230957, 4144.615234, 4141.025879, 4151.794922, 4157.436035, 4153.333496, 4151.794922, 4150.256348, 4152.307617, 4159.487305, 4158.974121, 4154.871582, 4151.282227, 4138.974121, 4135.384766, 4155.384766, 4174.358887, 4174.358887, 4163.589844, 4155.897461, 4150.769043, 4144.615234, 4140.512695, 4139.487305, 4134.358887, 4126.666504, 4120.512695, 4110.256348, 4101.025879, 4107.179688, 4121.025879, 4123.589844, 4121.538574, 4123.077148, 4117.436035, 4110.256348, 4117.436035, 4124.102539, 4120.0, 4120.0, 4125.641113, 4117.436035, 4109.743652, 4116.410156, 4121.025879, 4119.487305, 4118.974121, 4115.384766, 4116.922852, 4123.589844, 4122.563965, 4119.487305, 4123.589844, 4124.615234, 4123.589844, 4127.692383, 4134.358887, 4141.025879, 4141.538574, 4132.307617, 4122.563965, 4118.974121, 4120.512695, 4123.589844, 4124.615234, 4123.077148, 4121.025879, 4120.512695, 4118.974121, 4120.0, 4125.128418, 4124.615234, 4120.512695, 4122.05127, 4126.666504, 4127.179688, 4125.641113, 4124.615234, 4120.512695, 4116.922852, 4125.128418, 4141.025879, 4147.692383, 4146.666504, 4141.538574, 4127.692383, 4117.436035, 4120.512695, 4121.538574, 4120.512695, 4118.461426, 4110.769043, 4109.230957, 4122.563965, 4128.205078, 4119.487305, 4115.384766, 4118.974121, 4120.512695, 4112.307617, 4105.641113, 4115.897461, 4125.128418, 4115.897461, 4105.128418, 4107.179688, 4111.794922, 4109.230957, 4109.230957, 4117.436035, 4123.077148, 4117.436035, 4112.307617, 4114.871582, 4116.410156, 4118.974121, 4122.563965, 4122.05127, 4124.615234, 4125.641113, 4121.538574, 4125.641113, 4130.769043, 4123.077148, 4123.589844, 4133.333496, 4127.692383, 4122.563965, 4136.410156, 4144.102539, 4135.897461, 4134.358887, 4141.538574, 4141.025879, 4134.871582, 4134.871582, 4138.461426, 4137.436035, 4137.94873, 4142.05127, 4141.538574, 4136.410156, 4136.410156, 4137.94873, 4135.384766, 4138.974121, 4151.282227, 4155.897461, 4150.256348, 4149.743652, 4150.769043, 4141.538574, 4141.025879, 4148.205078, 4143.589844, 4138.461426, 4149.230957, 4157.94873, 4151.794922, 4144.102539, 4138.461426, 4134.871582, 4135.897461, 4137.436035, 4138.461426, 4139.487305, 4136.922852, 4129.743652, 4122.563965, 4123.589844, 4130.769043, 4137.94873, 4140.0, 4138.461426, 4138.461426, 4136.922852, 4135.897461, 4139.487305, 4142.05127, 4140.0, 4136.922852, 4135.384766, 4137.436035, 4138.461426, 4138.461426, 4138.974121, 4140.0, 4137.436035, 4133.333496, 4134.871582, 4137.436035, 4141.538574, 4152.307617, 4157.94873, 4145.641113, 4133.333496, 4140.512695, 4149.743652, 4150.769043, 4149.230957, 4144.615234, 4137.436035, 4136.922852, 4138.461426, 4135.384766, 4136.410156, 4138.974121, 4130.256348, 4121.025879, 4125.641113, 4127.692383, 4125.128418, 4133.846191, 4141.025879, 4140.512695, 4135.897461, 4127.692383, 4120.512695, 4120.512695, 4125.128418, 4131.794922, 4137.94873, 4136.410156, 4130.256348, 4130.256348, 4129.230957, 4125.641113, 4127.692383, 4129.230957, 4128.717773, 4132.820313, 4141.538574, 4139.487305, 4127.179688, 4120.512695, 4113.333496, 4105.128418, 4108.205078, 4115.384766, 4113.846191, 4110.769043, 4117.94873, 4129.743652, 4135.384766, 4129.743652, 4120.512695, 4115.384766, 4113.333496, 4116.922852, 4124.102539, 4120.0, 4114.358887, 4117.436035, 4122.563965, 4124.102539, 4122.05127, 4114.871582, 4111.282227, 4113.333496, 4113.846191, 4115.897461, 4119.487305, 4112.307617, 4104.102539, 4103.589844, 4105.641113, 4115.384766, 4126.153809, 4123.589844, 4123.077148, 4125.641113, 4122.05127, 4120.512695, 4120.512695, 4108.717773, 4101.538574, 4108.205078, 4115.897461, 4118.461426, 4093.846191, 4083.076904, 4180.0, 4309.743652, 4342.563965, 4331.282227, 4349.230957, 4354.871582, 4342.05127, 4341.025879, 4342.05127, 4341.538574, 4340.0, 4338.974121, 4348.205078, 4351.794922, 4343.589844, 4340.0, 4336.410156, 4329.230957, 4326.153809, 4317.436035, 4310.256348, 4320.512695, 4331.794922, 4327.179688, 4320.0, 4315.897461, 4316.922852, 4322.05127, 4316.922852, 4309.230957, 4309.743652, 4310.256348, 4310.769043, 4309.230957, 4305.641113, 4302.05127, 4298.461426, 4294.871582, 4291.794922, 4285.128418, 4280.512695, 4282.563965, 4276.410156, 4264.615234, 4263.589844, 4266.666504, 4264.615234, 4254.358887, 4239.487305, 4225.128418, 4222.563965, 4227.692383, 4222.05127, 4212.307617, 4213.333496, 4216.922852, 4216.922852, 4215.384766, 4207.179688, 4198.461426, 4203.077148, 4208.717773, 4207.692383, 4206.666504, 4200.0, 4191.794922, 4194.358887, 4202.05127, 4203.077148, 4196.410156, 4194.358887, 4196.410156, 4198.461426, 4200.512695, 4197.94873, 4187.179688, 4182.05127, 4181.025879, 4176.922852, 4177.94873, 4177.436035, 4170.256348, 4170.256348, 4172.820313, 4167.179688, 4166.666504, 4170.256348, 4166.153809, 4164.615234, 4171.794922, 4176.922852, 4172.820313, 4164.615234, 4170.256348, 4184.102539, 4183.077148, 4176.922852, 4182.563965, 4186.666504, 4184.102539, 4183.077148, 4177.94873, 4172.307617, 4174.871582, 4172.307617, 4170.256348, 4172.307617, 4168.717773, 4170.769043, 4181.538574, 4170.256348, 4151.794922, 4169.743652, 4201.025879, 4215.897461, 4228.205078, 4238.974121, 4237.94873, 4233.846191, 4234.358887, 4233.846191, 4230.256348, 4228.717773, 4239.487305, 4252.307617, 4248.205078, 4235.897461, 4227.692383, 4218.974121, 4213.333496, 4214.358887, 4214.871582, 4220.0, 4229.230957, 4233.333496, 4231.282227, 4225.641113, 4225.641113, 4229.230957, 4223.589844, 4214.871582, 4216.410156, 4218.974121, 4215.897461, 4212.307617, 4211.794922, 4213.846191, 4210.256348, 4200.512695, 4198.461426, 4201.538574, 4198.974121, 4197.94873, 4201.025879, 4200.0, 4200.512695, 4205.128418, 4206.666504, 4202.563965, 4201.538574, 4203.589844, 4201.025879, 4198.974121, 4201.538574, 4201.538574, 4198.461426, 4196.922852, 4193.846191, 4185.128418, 4181.538574, 4182.05127, 4181.538574, 4183.589844, 4189.230957, 4190.256348, 4185.641113, 4186.666504, 4198.461426, 4212.307617, 4212.820313, 4203.077148, 4202.05127, 4198.974121, 4180.512695, 4170.256348, 4182.05127, 4189.230957, 4184.102539, 4183.077148, 4182.563965, 4178.461426, 4171.794922, 4169.230957, 4176.410156, 4185.641113, 4184.615234, 4175.384766, 4170.256348, 4165.128418, 4157.436035, 4150.256348, 4154.358887, 4164.102539, 4162.563965, 4161.025879, 4163.589844, 4160.512695, 4153.333496, 4153.846191, 4154.358887, 4154.358887, 4156.922852, 4153.846191, 4151.794922, 4153.333496, 4151.794922, 4150.256348, 4152.307617, 4155.384766, 4156.410156, 4155.384766, 4155.384766, 4155.384766, 4155.897461, 4155.384766, 4150.256348, 4150.769043, 4154.358887, 4144.102539, 4135.384766, 4138.461426, 4132.820313, 4118.974121, 4110.769043, 4110.769043, 4111.794922, 4109.230957, 4105.128418, 4105.641113, 4107.692383, 4113.333496, 4116.410156, 4114.358887, 4114.871582, 4116.410156, 4116.922852, 4118.974121, 4116.922852, 4110.769043, 4106.666504, 4097.436035, 4087.692383, 4092.820557, 4094.871826, 4086.666748, 4095.384521, 4122.05127, 4142.563965, 4156.922852, 4165.128418, 4160.512695, 4156.410156, 4159.487305, 4156.922852, 4153.333496, 4150.769043, 4147.692383, 4145.641113, 4140.0, 4136.922852, 4140.0, 4140.0, 4137.436035, 4138.974121, 4143.077148, 4140.0, 4134.871582, 4136.410156, 4138.974121, 4136.410156, 4142.563965, 4156.922852, 4153.846191, 4144.102539, 4151.794922, 4162.05127, 4155.897461, 4144.615234, 4133.333496, 4123.077148, 4121.025879, 4122.05127, 4118.461426, 4124.102539, 4132.307617, 4127.692383, 4123.077148, 4124.615234, 4125.128418, 4123.077148, 4122.05127, 4128.205078, 4134.871582, 4128.717773, 4119.487305, 4122.563965, 4126.666504, 4124.102539, 4124.615234, 4123.589844, 4114.358887, 4110.256348, 4114.358887, 4108.205078, 4094.871826, 4095.897461, 4103.077148, 4105.641113, 4108.717773, 4110.256348, 4105.641113, 4104.102539, 4114.358887, 4123.589844, 4124.102539, 4120.0, 4111.794922, 4112.820313, 4118.461426, 4112.307617, 4103.077148, 4101.538574, 4101.025879, 4103.077148, 4107.692383, 4099.487305, 4093.333252, 4102.563965, 4105.641113, 4106.666504, 4114.871582, 4114.871582, 4106.666504, 4103.589844, 4101.538574, 4101.025879, 4103.589844, 4110.769043, 4116.922852, 4110.256348, 4100.0, 4102.563965, 4104.102539, 4108.717773, 4114.871582, 4110.256348, 4110.769043, 4129.743652, 4140.512695, 4138.974121, 4146.153809, 4155.384766, 4154.871582, 4154.871582, 4161.025879, 4158.974121, 4150.769043, 4156.410156, 4158.974121, 4147.692383, 4142.05127, 4140.0, 4138.974121, 4147.692383, 4150.769043, 4141.025879, 4133.846191, 4128.717773, 4123.589844, 4123.077148, 4114.871582, 4103.077148, 4105.641113, 4108.205078, 4103.077148, 4104.615234, 4107.179688, 4100.512695, 4098.461426, 4106.666504, 4110.256348, 4105.641113, 4103.077148, 4106.153809, 4103.589844, 4098.461426, 4101.025879, 4106.666504, 4105.641113, 4102.05127, 4104.102539, 4107.692383, 4103.589844, 4098.461426, 4100.512695, 4102.563965, 4103.589844, 4111.794922, 4111.794922, 4103.077148, 4104.615234, 4113.333496, 4115.384766, 4116.410156, 4116.410156, 4111.794922, 4111.282227, 4113.846191, 4112.307617, 4109.743652, 4107.692383, 4112.307617, 4118.461426, 4113.333496, 4109.230957, 4116.922852, 4113.846191, 4102.563965, 4103.589844, 4114.358887, 4119.487305, 4117.94873, 4114.871582, 4122.563965, 4135.384766, 4138.461426, 4138.461426, 4140.0, 4132.820313, 4121.538574, 4119.487305, 4118.974121, 4113.333496, 4114.871582, 4121.538574, 4125.128418, 4124.615234, 4121.538574, 4119.487305, 4121.538574, 4119.487305, 4116.410156, 4120.0, 4123.589844, 4130.256348, 4135.384766, 4126.666504, 4118.974121, 4126.666504, 4133.846191, 4133.846191, 4137.436035, 4142.05127, 4137.94873, 4127.692383, 4125.641113, 4133.333496, 4139.487305, 4134.871582, 4129.230957, 4130.256348, 4133.846191, 4137.94873, 4137.436035, 4130.256348, 4127.179688, 4132.820313, 4127.179688, 4116.922852, 4121.025879, 4124.615234, 4119.487305, 4116.410156, 4118.461426, 4129.230957, 4142.05127, 4143.589844, 4143.077148, 4144.102539, 4140.512695, 4143.077148, 4152.307617, 4152.820313, 4147.692383, 4147.692383, 4153.846191, 4158.974121, 4158.974121, 4156.922852, 4152.820313, 4150.769043, 4148.205078, 4143.589844, 4150.256348, 4166.153809, 4170.769043, 4167.179688, 4171.282227, 4172.307617, 4166.666504, 4165.641113, 4170.769043, 4174.871582, 4170.769043, 4166.153809, 4164.102539, 4156.922852, 4149.230957, 4152.307617, 4156.922852, 4161.538574, 4168.205078, 4173.333496, 4173.846191, 4171.282227, 4168.717773, 4169.230957, 4165.641113, 4156.922852, 4152.307617, 4155.384766, 4155.384766, 4153.333496, 4155.384766, 4156.922852, 4155.897461, 4152.820313, 4148.205078, 4146.666504, 4146.153809, 4138.461426, 4138.461426, 4149.743652, 4145.641113, 4137.436035, 4138.461426, 4134.871582, 4133.333496, 4136.410156, 4140.0, 4147.179688, 4149.230957, 4143.077148, 4146.153809, 4154.871582, 4152.820313, 4144.102539, 4136.922852, 4136.922852, 4144.102539, 4147.692383, 4151.282227, 4154.871582, 4150.256348, 4143.077148, 4145.128418, 4154.871582, 4155.384766, 4148.205078, 4155.384766, 4170.256348, 4168.205078, 4160.512695, 4166.153809, 4170.256348, 4168.717773, 4165.641113, 4156.922852, 4157.94873, 4165.128418, 4155.384766, 4146.153809, 4155.384766, 4156.410156, 4143.589844, 4135.897461, 4136.410156, 4137.94873, 4135.897461, 4136.410156, 4139.487305, 4138.974121, 4135.384766, 4137.436035, 4141.538574, 4133.846191, 4123.589844, 4127.692383, 4138.461426, 4135.897461, 4127.692383, 4126.666504, 4125.128418, 4122.05127, 4123.589844, 4126.153809, 4125.641113, 4125.128418, 4126.666504, 4126.153809, 4123.589844, 4120.512695, 4121.025879, 4123.077148, 4117.94873, 4106.666504, 4103.589844, 4109.230957, 4107.179688, 4107.179688, 4118.974121, 4128.717773, 4121.538574, 4111.282227, 4116.410156, 4122.05127, 4116.410156, 4115.897461, 4124.615234, 4120.0, 4113.333496, 4119.487305, 4115.384766, 4108.717773, 4115.897461, 4116.410156, 4109.230957, 4117.436035, 4127.692383, 4118.974121, 4111.282227, 4117.94873, 4123.589844, 4120.512695, 4125.128418, 4135.384766, 4130.256348, 4120.0, 4123.589844, 4124.615234, 4111.282227, 4107.692383, 4117.436035, 4122.05127, 4122.05127, 4124.102539, 4123.077148, 4121.538574, 4126.153809, 4126.666504, 4119.487305, 4120.0, 4128.205078, 4123.077148, 4111.282227, 4113.333496, 4123.077148, 4126.153809, 4122.563965, 4126.666504, 4132.820313, 4130.256348, 4126.153809, 4124.102539, 4116.410156, 4113.846191, 4121.538574, 4125.128418, 4129.230957, 4138.974121, 4136.410156, 4122.05127, 4120.512695, 4133.846191, 4143.077148, 4137.94873, 4128.205078, 4128.717773, 4135.897461, 4127.179688, 4116.922852, 4135.897461, 4146.666504, 4124.102539, 4116.410156, 4129.230957, 4126.153809, 4121.538574, 4130.256348, 4131.282227, 4123.589844, 4123.077148, 4130.256348, 4130.769043, 4123.077148, 4120.0, 4118.974121, 4115.384766, 4116.922852, 4118.461426, 4111.794922, 4111.794922, 4122.563965, 4128.205078, 4125.641113, 4118.974121, 4116.922852, 4121.025879, 4121.538574, 4117.436035, 4120.0, 4123.589844, 4123.077148, 4128.717773, 4131.794922, 4124.102539, 4120.512695, 4125.128418, 4126.666504, 4125.128418, 4120.512695, 4112.307617, 4106.666504, 4109.230957, 4114.871582, 4116.922852, 4114.871582, 4108.205078, 4094.358887, 4089.230713, 4102.05127, 4110.256348, 4105.128418, 4107.179688, 4120.0, 4126.153809, 4119.487305, 4111.282227, 4109.230957, 4109.230957, 4104.102539, 4099.487305, 4103.077148, 4106.666504, 4104.615234, 4103.589844, 4102.563965, 4096.922852, 4095.384521, 4096.922852, 4091.281982, 4091.281982, 4103.589844, 4103.077148, 4094.871826, 4100.0, 4100.0, 4091.794922, 4095.384521, 4093.333252, 4076.923096, 4072.307617, 4072.307617, 4060.0, 4055.897461, 4060.512939, 4055.897461, 4049.743652, 4051.794922, 4050.256348, 4035.384521, 4023.589844, 4017.94873, 4009.230713, 4005.641113, 4018.461426, 4040.0, 4048.718018, 4041.025635, 4041.538574, 4056.923096, 4057.94873, 4048.205078, 4048.718018, 4043.589844, 4036.923096, 4047.179443, 4056.923096, 4054.871826, 4055.384521, 4057.94873, 4052.307617, 4049.743652, 4048.205078, 4045.641113, 4049.230713, 4053.846191, 4054.871826, 4057.435791, 4063.076904, 4062.564209, 4057.94873, 4056.410156, 4048.718018, 4043.589844, 4046.666748, 4048.205078, 4052.307617, 4068.205078, 4080.512939, 4072.307617, 4063.589844, 4067.692383, 4073.333252, 4073.846191, 4075.384521, 4079.487061, 4072.307617, 4071.281982, 4085.641113, 4081.538574, 4062.564209, 4064.615479, 4071.794922, 4062.05127, 4060.512939, 4066.666748, 4066.153809, 4069.230713, 4072.307617, 4073.333252, 4081.025635, 4086.666748, 4083.589844, 4081.538574, 4081.538574, 4079.487061, 4076.923096, 4069.230713, 4061.538574, 4064.102539, 4064.615479, 4054.871826, 4050.256348, 4050.256348, 4042.564209, 4040.0, 4047.692383, 4044.102539, 4036.923096, 4040.0, 4037.435791, 4033.846191, 4043.076904, 4046.153809, 4037.94873, 4039.487061, 4044.615479, 4041.538574, 4044.102539, 4057.435791, 4062.564209, 4058.461426, 4050.769287, 4045.641113, 4060.0, 4086.666748, 4108.717773, 4134.358887, 4158.974121, 4169.230957, 4177.436035, 4186.666504, 4189.743652, 4185.128418, 4174.871582, 4169.230957, 4164.102539, 4152.307617, 4146.666504, 4154.871582, 4155.384766, 4150.769043, 4157.94873, 4162.05127, 4155.384766, 4148.205078, 4155.897461, 4167.179688, 4166.666504, 4164.615234, 4170.256348, 4173.333496, 4168.205078, 4173.333496, 4183.589844, 4186.153809, 4186.153809, 4182.05127, 4174.358887, 4175.384766, 4184.102539, 4184.615234, 4182.563965, 4188.717773, 4191.282227, 4186.666504, 4185.128418, 4188.205078, 4188.717773, 4184.615234, 4183.589844, 4187.179688, 4181.025879, 4168.205078, 4166.666504, 4171.282227, 4168.717773, 4169.230957, 4175.897461, 4173.846191, 4169.230957, 4168.205078, 4167.692383, 4170.256348, 4172.307617, 4166.666504, 4164.615234, 4173.333496, 4174.871582, 4168.205078, 4166.666504, 4169.743652, 4179.487305, 4187.179688, 4183.589844, 4176.410156, 4174.871582, 4172.307617, 4169.230957, 4171.282227, 4170.769043, 4162.563965, 4162.05127, 4165.641113, 4161.025879, 4155.897461, 4157.94873, 4150.256348, 4139.487305, 4143.589844, 4143.077148, 4135.384766, 4136.922852, 4142.05127, 4141.025879, 4138.461426, 4130.769043, 4121.538574, 4124.102539, 4128.205078, 4123.077148, 4117.94873, 4118.974121, 4128.205078, 4135.897461, 4136.410156, 4133.333496, 4128.717773, 4124.102539, 4121.025879, 4115.384766, 4103.077148, 4094.871826, 4096.410156, 4094.358887, 4093.846191, 4101.025879, 4102.05127, 4091.281982, 4089.743652, 4093.846191, 4093.333252, 4098.974121, 4109.230957, 4107.179688, 4106.666504, 4119.487305, 4118.461426, 4110.256348, 4113.846191, 4110.769043, 4099.487305, 4100.0, 4113.846191, 4118.974121, 4108.717773, 4101.538574, 4110.256348, 4116.922852, 4108.205078, 4103.589844, 4105.128418, 4105.641113, 4109.743652, 4111.282227, 4103.589844, 4089.230713, 4075.897461, 4063.589844, 4055.384521, 4056.923096, 4061.025635, 4062.05127, 4064.102539, 4067.692383, 4065.641113, 4061.538574, 4062.05127, 4065.641113, 4069.230713, 4066.153809, 4060.0, 4066.153809, 4076.923096, 4070.769287, 4062.05127, 4068.718018, 4068.718018, 4056.923096, 4064.102539, 4078.461426, 4073.846191, 4063.589844, 4060.512939, 4057.435791, 4059.487061, 4066.666748, 4068.205078, 4069.230713, 4070.256348, 4072.307617, 4078.461426, 4080.512939, 4073.846191, 4070.256348, 4071.794922, 4067.179443, 4061.025635, 4063.589844, 4069.743652, 4071.281982, 4073.846191, 4078.974365, 4078.974365, 4075.384521, 4074.871826, 4071.794922, 4061.538574, 4054.871826, 4053.333252, 4048.718018, 4047.179443, 4049.743652, 4043.589844, 4031.794922, 4023.589844, 4017.435791, 4017.94873, 4026.153809, 4027.692383, 4021.538574, 4016.923096, 4011.281982, 4001.025635, 4001.538574, 4009.230713, 4000.512939, 3986.666748, 3988.718018, 3991.794922, 3989.743652, 3995.897461, 3998.461426, 3988.718018, 3990.256348, 4001.025635, 3996.923096, 3986.666748, 3989.230713, 3996.410156, 3993.846191, 3986.153809, 3985.641113, 3988.205078, 3987.692383, 3987.179443, 3989.230713, 3988.205078, 3983.589844, 3982.05127, 3986.666748, 3989.230713, 3985.128174, 3985.128174, 3988.718018, 3986.666748, 3989.230713, 3995.384521, 3993.846191, 3994.871826, 3999.487061, 3993.846191, 3980.512939, 3970.256348, 3965.128174, 3964.102539, 3962.05127, 3958.974365, 3957.94873, 3956.923096, 3958.461426, 3961.025635, 3958.461426, 3955.897461, 3956.923096, 3957.94873, 3953.846191, 3952.307617, 3958.461426, 3962.05127, 3958.974365, 3957.435791, 3955.384521, 3952.820557, 3961.025635, 3972.307617, 3977.435791, 3973.333252, 3965.641113, 3967.179443, 3974.871826, 3968.718018, 3958.461426, 3957.94873, 3951.281982, 3943.076904, 3953.846191, 3964.615479, 3962.564209, 3958.461426, 3957.435791, 3958.461426, 3958.974365, 3956.923096, 3959.487061, 3962.564209, 3956.410156, 3958.974365, 3968.205078, 3966.666748, 3966.666748, 3969.230713, 3963.589844, 3962.564209, 3971.281982, 3973.333252, 3969.230713, 3970.256348, 3969.230713, 3966.666748, 3966.153809, 3965.128174, 3968.718018, 3973.333252, 3966.666748, 3961.538574, 3975.897461, 3991.281982, 3993.333252, 3989.743652, 3980.512939, 3972.820557, 3972.307617, 3975.384521, 3978.461426, 3980.512939, 3978.461426, 3976.923096, 3977.94873, 3981.025635, 3981.538574, 3971.794922, 3971.281982, 3988.718018, 3995.897461, 3988.718018, 3987.692383, 3994.358887, 3989.743652, 3976.410156, 3970.256348, 3973.846191, 3975.384521, 3974.358887, 3980.0, 3982.05127, 3974.358887, 3970.256348, 3977.94873, 3985.641113, 3983.076904, 3975.897461, 3970.769287, 3973.333252, 3980.512939, 3985.128174, 3986.153809, 3985.641113, 3982.564209, 3981.538574, 3987.692383, 3990.769287, 3990.769287, 3991.281982, 3987.692383, 3988.718018, 3985.641113, 3972.820557, 3980.0, 4007.692383, 4013.333252, 4004.615479, 4008.718018, 4010.256348, 4003.589844, 4001.538574, 4000.0, 4002.05127, 4015.384521, 4024.615479, 4020.512939, 4021.025635, 4027.179443, 4027.692383, 4022.564209, 4019.487061, 4018.974365, 4019.487061, 4024.615479, 4031.794922, 4035.897461, 4038.974365, 4042.05127, 4043.589844, 4036.410156, 4024.102539, 4033.846191, 4069.230713, 4091.281982, 4094.871826, 4105.128418, 4108.205078, 4092.307617, 4079.487061, 4076.410156, 4081.025635, 4088.205078, 4090.256348, 4085.641113, 4080.0, 4074.871826, 4068.205078, 4065.128174, 4066.666748, 4072.307617, 4081.025635, 4086.153809, 4087.179443, 4085.641113, 4090.256348, 4094.871826, 4087.692383, 4081.538574, 4085.641113, 4085.128174, 4077.94873, 4080.0, 4082.564209, 4075.384521, 4071.794922, 4076.923096, 4083.589844, 4087.179443, 4090.256348, 4090.769287, 4083.076904, 4075.897461, 4079.487061, 4078.461426, 4074.358887, 4078.974365, 4081.538574, 4079.487061, 4079.487061, 4081.025635, 4085.128174, 4091.281982, 4091.794922, 4084.615479, 4073.333252, 4071.794922, 4088.205078, 4106.666504, 4111.282227, 4108.717773, 4105.641113, 4109.743652, 4116.922852, 4113.846191, 4106.153809, 4105.128418, 4112.820313, 4122.563965, 4122.05127, 4112.820313, 4111.794922, 4118.974121, 4116.922852, 4109.743652, 4110.769043, 4109.230957, 4099.487305, 4096.410156, 4100.512695, 4101.025879, 4103.077148, 4107.179688, 4109.230957, 4103.589844, 4090.769287, 4094.358887, 4122.563965, 4140.0, 4133.333496, 4128.717773, 4137.94873, 4137.94873, 4124.102539, 4117.94873, 4126.153809, 4122.563965, 4110.256348, 4110.256348, 4120.0, 4121.538574, 4112.307617, 4105.128418, 4110.769043, 4118.461426, 4120.512695, 4120.0, 4116.410156, 4110.256348, 4107.692383, 4107.179688, 4102.563965, 4100.512695, 4107.692383, 4111.282227, 4101.025879, 4097.94873, 4106.153809, 4098.461426, 4085.641113, 4093.846191, 4106.153809, 4105.128418, 4104.102539, 4104.615234, 4106.666504, 4114.871582, 4122.563965, 4124.615234, 4122.563965, 4117.94873, 4116.922852, 4122.05127, 4124.102539, 4118.461426, 4115.897461, 4117.94873, 4114.358887, 4107.692383, 4102.563965, 4092.820557, 4086.666748, 4093.333252, 4096.410156, 4094.358887, 4097.94873, 4097.94873, 4090.769287, 4086.666748, 4095.897461, 4105.128418, 4102.563965, 4099.487305, 4106.153809, 4108.717773, 4105.128418, 4106.153809, 4104.615234, 4109.230957, 4122.05127, 4114.358887, 4102.563965, 4116.922852, 4131.282227, 4122.563965, 4117.436035, 4123.589844, 4124.102539, 4123.077148, 4123.077148, 4119.487305, 4118.461426, 4121.538574, 4120.512695, 4123.589844, 4135.897461, 4140.512695, 4138.974121, 4138.974121, 4129.230957, 4118.974121, 4124.615234, 4128.205078, 4114.871582, 4107.179688, 4107.692383, 4092.820557, 4072.820557, 4060.0, 4045.128174, 4038.461426, 4048.718018, 4053.333252, 4049.230713, 4047.179443, 4044.102539, 4047.179443, 4054.358887, 4047.179443, 4036.410156, 4038.461426, 4047.179443, 4052.820557, 4052.820557, 4045.641113, 4035.897461, 4032.820557, 4035.897461, 4038.461426, 4037.435791, 4038.461426, 4036.410156, 4020.0, 4005.128174, 4008.205078, 4017.435791, 4017.94873, 4017.435791, 4022.05127, 4021.025635, 4013.333252, 4011.281982, 4014.358887, 4016.923096, 4019.487061, 4014.358887, 4006.666748, 4006.666748, 4016.410156, 4025.128174, 4026.666748, 4023.589844, 4022.05127, 4024.615479, 4025.128174, 4023.589844, 4021.025635, 4018.974365, 4020.0, 4021.025635, 4022.564209, 4022.564209, 4020.512939, 4020.0, 4017.435791, 4014.871826, 4021.538574, 4028.205078, 4023.589844, 4015.384521, 4017.435791, 4025.641113, 4030.769287, 4031.281982, 4031.794922, 4034.358887, 4034.358887, 4034.871826, 4036.410156, 4037.94873, 4047.179443, 4054.871826, 4053.846191, 4049.230713, 4044.615479, 4045.128174, 4049.230713, 4037.94873, 4026.666748, 4045.641113, 4074.358887, 4089.743652, 4105.128418, 4128.717773, 4145.641113, 4146.153809, 4142.05127, 4137.436035, 4127.179688, 4124.102539, 4133.846191, 4138.974121, 4136.922852, 4131.282227, 4123.077148, 4127.179688, 4133.333496, 4129.230957, 4128.205078, 4130.769043, 4123.077148, 4114.871582, 4124.615234, 4134.358887, 4127.179688, 4119.487305, 4124.102539, 4124.102539, 4114.871582, 4122.563965, 4138.974121, 4140.512695, 4136.410156, 4143.589844, 4148.205078, 4140.0, 4135.897461, 4137.436035, 4134.871582, 4135.384766, 4138.461426, 4138.461426, 4140.0, 4140.0, 4137.436035, 4144.615234, 4148.205078, 4141.025879, 4145.641113, 4148.717773, 4144.102539, 4147.692383, 4147.692383, 4136.922852, 4134.871582, 4139.487305, 4139.487305, 4135.897461, 4129.743652, 4127.692383, 4127.692383, 4125.128418, 4133.846191, 4144.102539, 4133.846191, 4117.436035, 4114.871582, 4117.436035, 4118.461426, 4116.922852, 4110.256348, 4107.692383, 4115.897461, 4122.05127, 4114.358887, 4110.256348, 4114.871582, 4122.05127, 4123.077148, 4114.358887, 4110.769043, 4122.05127, 4135.897461, 4140.0, 4131.794922, 4120.512695, 4118.974121, 4126.666504, 4124.102539, 4124.102539, 4131.282227, 4127.692383, 4120.0, 4120.512695, 4123.077148, 4120.0, 4120.0, 4122.05127, 4124.102539, 4122.563965, 4121.538574, 4132.307617, 4135.384766, 4124.615234, 4122.05127, 4123.077148, 4117.94873, 4122.05127, 4125.641113, 4116.922852, 4114.871582, 4122.05127, 4122.05127, 4116.410156, 4114.871582, 4120.0, 4126.666504, 4125.641113, 4120.512695, 4122.05127, 4125.128418, 4122.563965, 4118.974121, 4118.974121, 4120.0, 4127.179688, 4136.410156, 4133.846191, 4126.153809, 4127.692383, 4124.102539, 4107.179688, 4105.128418, 4115.897461, 4108.717773, 4102.563965, 4115.384766, 4122.05127, 4116.922852, 4118.974121, 4118.461426, 4105.128418, 4101.538574, 4110.256348, 4107.692383, 4105.641113, 4118.974121, 4120.512695, 4104.102539, 4102.05127, 4110.256348, 4106.666504, 4105.641113, 4110.256348, 4109.230957, 4113.846191, 4118.461426, 4109.743652, 4108.205078, 4116.410156, 4114.871582, 4109.743652, 4107.179688, 4103.589844, 4103.589844, 4104.102539, 4097.94873, 4092.820557, 4094.871826, 4099.487305, 4101.025879, 4095.384521, 4089.743652, 4089.230713, 4096.410156, 4108.717773, 4125.128418, 4136.922852, 4130.769043, 4120.0, 4118.974121, 4122.563965, 4129.230957, 4137.94873, 4138.461426, 4135.384766, 4140.512695, 4138.974121, 4122.563965, 4104.615234, 4102.563965, 4119.487305, 4136.410156, 4138.461426, 4136.922852, 4134.871582, 4131.794922, 4131.282227, 4129.230957, 4125.641113, 4126.153809, 4124.102539, 4122.563965, 4127.179688, 4128.205078, 4116.410156, 4107.179688, 4108.205078, 4110.256348, 4105.641113, 4103.589844, 4114.871582, 4120.512695, 4112.307617, 4108.205078, 4109.743652, 4110.256348, 4113.846191, 4122.563965, 4124.102539, 4121.025879, 4122.563965, 4123.589844, 4115.897461, 4107.692383, 4114.871582, 4124.615234, 4120.0, 4115.897461, 4123.589844, 4121.538574, 4110.256348, 4109.743652, 4112.307617, 4107.692383, 4105.128418, 4105.128418, 4108.205078, 4120.0, 4125.641113, 4123.077148, 4125.128418, 4125.128418, 4118.461426, 4119.487305, 4122.05127, 4121.025879, 4122.05127, 4122.563965, 4120.512695, 4118.461426, 4120.0, 4124.615234, 4124.615234, 4122.563965, 4125.641113, 4122.563965, 4111.794922, 4113.846191, 4122.05127, 4122.563965, 4117.436035, 4112.307617, 4110.256348, 4107.179688, 4102.563965, 4100.0, 4098.461426, 4095.897461, 4100.0, 4107.692383, 4106.153809, 4095.384521, 4086.666748, 4086.666748, 4095.897461, 4100.512695, 4095.897461, 4091.794922, 4092.307617, 4093.333252, 4090.256348, 4090.769287, 4098.461426, 4099.487305, 4095.897461, 4102.05127, 4108.717773, 4100.512695, 4093.333252, 4097.94873, 4104.615234, 4102.563965, 4093.846191, 4089.743652, 4089.743652, 4091.281982, 4099.487305, 4107.692383, 4108.205078, 4105.641113, 4105.128418, 4111.794922, 4123.077148, 4131.282227, 4134.871582, 4141.538574, 4147.692383, 4153.846191, 4158.974121, 4158.461426, 4160.512695, 4168.717773, 4174.358887, 4175.897461, 4173.333496, 4175.384766, 4185.641113, 4186.666504, 4175.897461, 4175.384766, 4172.820313, 4155.897461, 4145.128418, 4138.974121, 4131.794922, 4138.461426, 4140.0, 4125.641113, 4126.666504, 4137.94873, 4131.794922, 4119.487305, 4113.846191, 4113.333496, 4113.846191, 4114.358887, 4114.871582, 4115.897461, 4110.256348, 4101.025879, 4101.538574, 4104.102539, 4106.666504, 4109.743652, 4105.128418, 4103.589844, 4107.692383, 4104.615234, 4095.897461, 4100.0, 4110.256348, 4109.230957, 4107.179688, 4109.743652, 4105.128418, 4101.025879, 4106.153809, 4110.769043, 4108.205078, 4104.102539, 4105.641113, 4107.692383, 4103.077148, 4096.410156, 4101.538574, 4103.077148, 4090.769287, 4093.846191, 4107.692383, 4099.487305, 4085.128174, 4088.205078, 4094.358887, 4095.897461, 4100.0, 4103.077148, 4105.128418, 4106.666504, 4105.641113, 4101.025879, 4096.410156, 4092.307617, 4090.769287, 4092.307617, 4091.281982, 4088.205078, 4089.230713, 4091.794922, 4087.179443, 4083.589844, 4088.205078, 4090.769287, 4087.179443, 4087.692383, 4090.256348, 4088.205078, 4090.769287, 4098.461426, 4093.333252, 4082.564209, 4085.128174, 4090.256348, 4083.076904, 4074.358887, 4073.846191, 4075.384521, 4072.307617, 4067.692383, 4067.692383, 4065.128174, 4061.025635, 4065.641113, 4067.179443, 4058.461426, 4058.461426, 4064.615479, 4060.0, 4058.461426, 4063.076904, 4055.897461, 4042.05127, 4037.435791, 4040.0, 4031.794922, 4017.94873, 4021.025635, 4033.846191, 4034.871826, 4030.769287, 4029.230713, 4028.205078, 4028.718018, 4024.102539, 4019.487061, 4016.923096, 4012.820557, 4009.743652, 4007.692383, 4004.102539, 3997.94873, 3993.846191, 3997.435791, 4003.589844, 4000.512939, 3994.358887, 3992.820557, 3993.333252, 3992.820557, 3994.358887, 3995.384521, 3994.358887, 3993.846191, 3994.871826, 3992.820557, 3994.871826, 4005.641113, 4011.281982, 4011.281982, 4011.281982, 4003.076904, 3997.435791, 4007.692383, 4015.897461, 4017.435791, 4017.435791, 4007.692383, 4000.512939, 4010.256348, 4017.435791, 4007.179443, 4001.025635, 4009.743652, 4013.846191, 4008.205078, 4004.615479, 4010.256348, 4016.923096, 4018.461426, 4016.923096, 4015.384521, 4017.94873, 4020.512939, 4017.94873, 4016.923096, 4022.05127, 4025.641113, 4024.102539, 4025.641113, 4028.718018, 4030.256348, 4035.897461, 4041.538574, 4041.538574, 4038.974365, 4036.410156, 4032.820557, 4034.358887, 4037.94873, 4035.384521, 4032.307617, 4035.897461, 4040.0, 4037.94873, 4034.871826, 4039.487061, 4044.615479, 4044.615479, 4047.692383, 4049.230713, 4047.179443, 4052.307617, 4059.487061, 4057.94873, 4057.435791, 4059.487061, 4059.487061, 4062.05127, 4064.102539, 4061.538574, 4057.94873, 4061.025635, 4069.743652, 4070.256348, 4068.718018, 4076.410156, 4080.0, 4072.820557, 4071.794922, 4075.897461, 4074.871826, 4076.410156, 4083.076904, 4087.179443, 4089.743652, 4086.666748, 4081.025635, 4081.538574, 4081.025635, 4077.94873, 4082.05127, 4088.718018, 4083.076904, 4075.897461, 4078.974365, 4082.564209, 4078.461426, 4078.974365, 4086.666748, 4084.615479, 4078.461426, 4083.076904, 4086.153809, 4079.487061, 4079.487061, 4087.692383, 4092.307617, 4095.897461, 4098.974121, 4099.487305, 4096.410156, 4091.794922, 4094.871826, 4103.589844, 4106.666504, 4105.128418, 4107.692383, 4108.205078, 4111.794922, 4120.512695, 4124.102539, 4121.025879, 4115.897461, 4112.307617, 4106.153809, 4104.102539, 4112.307617, 4120.0, 4121.025879, 4120.0, 4117.94873, 4117.436035, 4123.589844, 4125.641113, 4117.94873, 4122.05127, 4132.820313, 4131.794922, 4125.641113, 4123.077148, 4120.512695, 4120.512695, 4129.743652, 4132.307617, 4129.230957, 4135.384766, 4139.487305, 4138.974121, 4136.410156, 4129.743652, 4127.179688, 4128.205078, 4126.666504, 4130.256348, 4137.94873, 4135.384766, 4133.846191, 4137.94873, 4132.820313, 4123.077148, 4123.077148, 4130.256348, 4135.897461, 4144.102539, 4151.282227, 4145.641113, 4135.897461, 4137.94873, 4138.974121, 4127.179688, 4113.846191, 4105.641113, 4101.538574, 4103.589844, 4110.256348, 4110.769043, 4105.128418, 4102.563965, 4102.563965, 4103.589844, 4106.153809, 4112.307617, 4116.922852, 4112.820313, 4102.563965, 4096.922852, 4098.974121, 4097.436035, 4096.922852, 4100.512695, 4095.897461, 4085.128174, 4085.641113, 4092.307617, 4091.794922, 4096.922852, 4106.666504, 4106.666504, 4104.102539, 4105.641113, 4108.205078, 4107.179688, 4106.666504, 4103.589844, 4097.94873, 4097.436035, 4104.615234, 4110.256348, 4106.153809, 4102.563965, 4105.128418, 4110.256348, 4116.922852, 4118.461426, 4113.846191, 4104.615234, 4093.333252, 4093.846191, 4106.153809, 4110.769043, 4107.179688, 4106.153809, 4103.077148, 4095.384521, 4095.897461, 4098.974121, 4100.0, 4104.102539, 4105.128418, 4097.436035, 4091.794922, 4087.179443, 4082.564209, 4085.128174, 4091.794922, 4096.922852, 4104.102539, 4108.205078, 4109.230957, 4112.307617, 4108.717773, 4102.563965, 4106.666504, 4110.256348, 4109.230957, 4108.717773, 4103.589844, 4098.974121, 4096.922852, 4094.358887, 4090.769287, 4088.718018, 4092.820557, 4102.05127, 4110.256348, 4110.256348, 4106.666504, 4107.692383, 4115.897461, 4115.897461, 4100.512695, 4092.307617, 4098.974121, 4105.128418, 4107.179688, 4109.230957, 4108.717773, 4100.512695, 4095.384521, 4100.512695, 4101.538574, 4099.487305, 4106.666504, 4110.256348, 4106.666504, 4109.230957, 4112.820313, 4105.128418, 4098.461426, 4100.0, 4102.05127, 4099.487305, 4097.94873, 4098.461426, 4100.0, 4099.487305, 4100.512695, 4096.410156, 4086.666748, 4085.128174, 4091.281982, 4095.384521, 4092.820557, 4087.692383, 4086.153809, 4084.102539, 4074.358887, 4064.615479, 4066.153809, 4071.794922, 4074.871826, 4080.0, 4081.025635, 4077.435791, 4073.333252, 4071.794922, 4077.94873, 4087.179443, 4086.666748, 4080.512939, 4082.564209, 4087.179443, 4083.589844, 4076.923096, 4076.410156, 4081.025635, 4081.538574, 4073.846191, 4073.333252, 4086.666748, 4094.358887, 4087.179443, 4084.102539, 4091.281982, 4091.281982, 4081.025635, 4073.846191, 4078.461426, 4084.615479, 4083.076904, 4080.0, 4079.487061, 4086.153809, 4094.871826, 4090.256348, 4077.94873, 4076.410156, 4078.461426, 4078.461426, 4078.974365, 4075.897461, 4070.769287, 4066.666748, 4063.076904, 4066.666748, 4069.230713, 4061.025635, 4059.487061, 4069.230713, 4069.743652, 4062.564209, 4063.589844, 4067.692383, 4065.128174, 4065.641113, 4071.281982, 4072.307617, 4069.230713, 4067.179443, 4062.564209, 4058.974365, 4063.076904, 4068.205078, 4067.692383, 4065.128174, 4063.076904, 4066.666748, 4075.897461, 4079.487061, 4071.794922, 4060.512939, 4061.025635, 4068.718018, 4070.256348, 4065.641113, 4064.102539, 4061.025635, 4055.384521, 4055.384521, 4062.564209, 4061.538574, 4058.461426, 4065.641113, 4067.179443, 4057.94873, 4056.410156, 4062.564209, 4065.641113, 4070.769287, 4077.435791, 4074.358887, 4069.230713, 4072.820557, 4074.871826, 4068.205078, 4067.692383, 4075.897461, 4074.358887, 4067.179443, 4068.718018, 4074.358887, 4079.487061, 4084.615479, 4087.692383, 4083.589844, 4075.384521, 4074.871826, 4080.0, 4079.487061, 4075.384521, 4070.769287, 4068.718018, 4069.743652, 4070.769287, 4070.256348, 4074.871826, 4075.897461, 4070.769287, 4072.820557, 4077.94873, 4071.794922, 4062.564209, 4067.692383, 4076.923096, 4078.461426, 4074.358887, 4068.205078, 4069.230713, 4074.871826, 4077.435791, 4079.487061, 4084.102539, 4085.641113, 4087.692383, 4095.384521, 4104.615234, 4111.794922, 4117.436035, 4117.94873, 4111.282227, 4106.153809, 4104.102539, 4096.410156, 4088.718018, 4087.692383, 4089.230713, 4086.153809, 4074.358887, 4061.538574, 4065.641113, 4074.871826, 4071.794922, 4065.128174, 4063.589844, 4065.128174, 4064.102539, 4063.589844, 4070.769287, 4074.358887, 4069.230713, 4068.718018, 4078.461426, 4084.102539, 4080.512939, 4071.281982, 4064.102539, 4065.641113, 4064.102539, 4059.487061, 4063.076904, 4060.512939, 4055.897461, 4068.205078, 4080.0, 4070.769287, 4065.641113, 4073.333252, 4074.871826, 4078.461426, 4085.128174, 4074.871826, 4063.589844, 4070.769287, 4079.487061, 4077.435791, 4078.461426, 4076.923096, 4069.230713, 4070.256348, 4074.871826, 4071.794922, 4064.102539, 4064.615479, 4071.794922, 4075.897461, 4073.846191, 4071.794922, 4075.384521, 4073.846191, 4066.153809, 4064.615479, 4071.794922, 4076.923096, 4070.769287, 4063.076904, 4066.153809, 4070.769287, 4065.641113, 4062.564209, 4066.153809, 4064.102539, 4056.410156, 4056.410156, 4060.0, 4061.538574, 4064.102539, 4068.205078, 4065.128174, 4063.076904, 4068.718018, 4075.897461, 4078.974365, 4076.410156, 4072.820557, 4077.94873, 4083.589844, 4076.410156, 4068.718018, 4071.794922, 4075.384521, 4072.307617, 4070.256348, 4069.230713, 4057.435791, 4049.743652, 4062.564209, 4080.0, 4087.179443, 4088.718018, 4088.718018, 4086.666748, 4091.794922, 4094.871826, 4087.179443, 4077.435791, 4080.512939, 4089.743652, 4093.333252, 4090.256348, 4080.0, 4076.923096, 4086.153809, 4090.769287, 4087.692383, 4090.769287, 4096.410156, 4093.846191, 4089.230713, 4087.179443, 4091.794922, 4092.820557, 4087.179443, 4094.871826, 4104.102539, 4093.333252, 4089.230713, 4100.512695, 4097.436035, 4086.153809, 4087.692383, 4096.922852, 4101.025879, 4097.94873, 4090.256348, 4089.230713, 4099.487305, 4102.563965, 4097.94873, 4100.0, 4106.153809, 4107.692383, 4104.615234, 4095.897461, 4089.230713, 4100.512695, 4111.282227, 4106.153809, 4104.102539, 4115.384766, 4124.615234, 4120.512695, 4114.871582, 4118.974121, 4127.179688, 4133.333496, 4141.025879, 4142.05127, 4126.666504, 4109.230957, 4105.128418, 4106.666504, 4104.102539, 4104.102539, 4109.743652, 4116.410156, 4123.589844, 4126.666504, 4117.94873, 4110.256348, 4114.871582, 4113.333496, 4105.641113, 4112.820313, 4125.128418, 4121.025879, 4117.436035, 4127.179688, 4135.897461, 4138.461426, 4136.922852, 4133.333496, 4125.641113, 4121.025879, 4123.077148, 4122.05127, 4122.05127, 4125.128418, 4124.102539, 4122.05127, 4122.05127, 4122.05127, 4127.179688, 4130.769043, 4126.666504, 4130.769043, 4136.410156, 4131.282227, 4131.282227, 4134.358887, 4127.179688, 4120.512695, 4118.461426, 4114.358887, 4117.436035, 4122.05127, 4121.538574, 4116.922852, 4109.230957, 4110.769043, 4124.615234, 4127.692383, 4118.461426, 4117.94873, 4118.974121, 4113.333496, 4108.205078, 4107.179688, 4120.0, 4137.436035, 4141.538574, 4138.461426, 4134.358887, 4124.102539, 4120.0, 4126.666504, 4126.666504, 4118.974121, 4116.410156, 4115.897461, 4108.205078, 4105.128418, 4117.94873, 4125.641113, 4119.487305, 4126.153809, 4140.512695, 4135.384766, 4124.615234, 4125.128418, 4126.153809, 4122.563965, 4121.538574, 4125.128418, 4128.717773, 4127.692383, 4124.615234, 4122.563965, 4118.461426, 4116.410156, 4121.025879, 4120.0, 4121.025879, 4133.846191, 4140.512695, 4136.410156, 4136.410156, 4138.974121, 4137.436035, 4136.922852, 4137.94873, 4139.487305, 4140.0, 4137.94873, 4137.94873, 4139.487305, 4137.436035, 4135.384766, 4134.871582, 4131.794922, 4123.077148, 4118.974121, 4128.205078, 4132.820313, 4125.641113, 4120.0, 4123.589844, 4127.692383, 4124.615234, 4125.641113, 4134.358887, 4140.512695, 4138.461426, 4136.922852, 4140.0, 4138.461426, 4140.512695, 4150.769043, 4152.307617, 4141.025879, 4134.871582, 4137.94873, 4137.94873, 4134.871582, 4137.436035, 4140.512695, 4138.974121, 4137.436035, 4138.974121, 4140.0, 4138.461426, 4132.820313, 4123.077148, 4117.94873, 4119.487305, 4126.666504, 4136.410156, 4142.05127, 4137.94873, 4130.256348, 4125.641113, 4121.538574, 4126.153809, 4137.436035, 4137.94873, 4131.282227, 4134.358887, 4133.846191, 4126.666504, 4128.717773, 4133.846191, 4134.871582, 4136.922852, 4145.641113, 4149.230957, 4141.538574, 4132.307617, 4132.820313, 4135.897461, 4133.333496, 4134.871582, 4141.025879, 4134.358887, 4119.487305, 4126.666504, 4152.307617, 4166.153809, 4162.05127, 4154.358887, 4151.282227, 4155.384766, 4155.897461, 4146.666504, 4145.641113, 4150.256348, 4145.641113, 4138.461426, 4135.897461, 4128.717773, 4122.05127, 4118.974121, 4110.769043, 4104.102539, 4107.179688, 4112.307617, 4113.333496, 4113.333496, 4106.153809, 4094.358887, 4094.358887, 4100.512695, 4094.358887, 4087.179443, 4090.769287, 4095.384521, 4102.05127, 4110.769043, 4107.179688, 4101.025879, 4102.563965, 4103.589844, 4105.128418, 4104.615234, 4100.512695, 4102.05127, 4107.692383, 4107.692383, 4109.743652, 4116.410156, 4113.333496, 4105.641113, 4105.641113, 4110.256348, 4111.282227, 4108.717773, 4103.589844, 4101.538574, 4106.666504, 4110.256348, 4113.846191, 4117.436035, 4115.384766, 4109.230957, 4107.179688, 4109.743652, 4111.794922, 4110.256348, 4106.666504, 4105.128418, 4107.692383, 4106.153809, 4106.153809, 4108.717773, 4108.717773, 4106.153809, 4110.769043, 4121.025879, 4119.487305, 4112.307617, 4112.820313, 4118.461426, 4118.974121, 4122.563965, 4130.256348, 4127.692383, 4120.0, 4121.025879, 4126.153809, 4127.692383, 4127.179688, 4131.794922, 4137.436035, 4132.820313, 4127.692383, 4133.333496, 4138.461426, 4134.358887, 4134.871582, 4139.487305, 4134.358887, 4123.077148, 4118.974121, 4127.179688, 4134.871582, 4134.358887, 4136.410156, 4137.94873, 4132.307617, 4130.769043, 4135.897461, 4133.846191, 4130.256348, 4133.846191, 4140.512695, 4150.256348, 4156.410156, 4150.256348, 4149.743652, 4157.436035, 4157.436035, 4153.333496, 4153.846191, 4152.820313, 4146.153809, 4141.538574, 4142.563965, 4139.487305, 4128.717773, 4128.717773, 4133.333496, 4115.384766, 4101.538574, 4113.846191, 4115.897461, 4104.615234, 4107.179688, 4109.230957, 4106.153809, 4107.692383, 4111.282227, 4112.820313, 4113.333496, 4115.384766, 4122.563965, 4130.769043, 4132.820313, 4137.94873, 4140.0, 4137.94873, 4138.974121, 4139.487305, 4140.512695, 4139.487305, 4134.358887, 4132.820313, 4136.922852, 4134.358887, 4130.256348, 4135.897461, 4143.077148, 4137.94873, 4123.077148, 4122.563965, 4133.333496, 4131.794922, 4122.05127, 4120.0, 4125.641113, 4128.717773, 4133.333496, 4137.436035, 4128.205078, 4109.230957, 4103.077148, 4105.641113, 4100.512695, 4101.025879, 4109.230957, 4109.230957, 4109.743652, 4114.358887, 4107.692383, 4100.512695, 4100.0, 4099.487305, 4101.025879, 4104.615234, 4109.230957, 4119.487305, 4124.615234, 4116.922852, 4113.333496, 4111.282227, 4100.0, 4102.05127, 4121.025879, 4134.358887, 4140.512695, 4137.436035, 4127.179688, 4128.205078, 4136.410156, 4134.871582, 4127.179688, 4125.641113, 4128.205078, 4132.307617, 4137.94873, 4141.538574, 4142.563965, 4140.0, 4136.410156, 4139.487305, 4140.512695, 4137.436035, 4136.410156, 4137.436035, 4133.333496, 4123.589844, 4116.410156, 4117.94873, 4127.179688, 4127.179688, 4116.410156, 4114.871582, 4122.05127, 4124.615234, 4121.025879, 4117.436035, 4115.897461, 4117.436035, 4125.641113, 4132.307617, 4131.794922, 4132.820313, 4138.461426, 4138.461426, 4133.333496, 4142.05127, 4154.358887, 4150.256348, 4144.102539, 4136.922852, 4126.666504, 4128.205078, 4132.820313, 4128.717773, 4128.205078, 4126.666504, 4118.461426, 4120.512695, 4125.128418, 4118.974121, 4121.025879, 4126.153809, 4125.128418, 4121.025879, 4120.512695, 4127.179688, 4123.077148, 4111.794922, 4116.922852, 4127.179688, 4116.410156, 4108.717773, 4119.487305, 4128.205078, 4125.641113, 4121.538574, 4129.230957, 4136.410156, 4125.641113, 4122.05127, 4136.410156, 4141.025879, 4135.384766, 4138.461426, 4141.538574, 4135.384766, 4127.692383, 4121.025879, 4117.94873, 4117.436035, 4120.0, 4124.615234, 4123.077148, 4117.94873, 4121.538574, 4127.179688, 4125.128418, 4126.666504, 4136.410156, 4138.974121, 4135.384766, 4136.922852, 4136.922852, 4135.384766, 4137.94873, 4130.256348, 4115.384766, 4113.846191, 4118.974121, 4123.077148, 4130.256348, 4136.410156, 4136.922852, 4133.846191, 4130.256348, 4126.666504, 4124.102539, 4126.666504, 4132.820313, 4133.333496, 4125.128418, 4120.512695, 4121.025879, 4112.820313, 4107.692383, 4116.410156, 4117.94873, 4111.282227, 4112.307617, 4113.333496, 4110.256348, 4112.820313, 4110.769043, 4106.666504, 4107.692383, 4103.589844, 4094.871826, 4092.307617, 4092.307617, 4088.205078, 4086.666748, 4092.307617, 4097.94873, 4097.436035, 4094.358887, 4090.769287, 4093.333252, 4100.512695, 4097.94873, 4098.974121, 4108.205078, 4107.179688, 4104.102539, 4104.102539, 4093.846191, 4077.94873, 4083.076904, 4101.538574, 4105.641113, 4095.897461, 4096.410156, 4106.666504, 4108.205078, 4103.589844, 4107.179688, 4112.307617, 4108.205078, 4106.666504, 4116.922852, 4127.179688, 4126.666504, 4127.179688, 4132.307617, 4132.820313, 4130.256348, 4136.922852, 4147.692383, 4141.538574, 4136.922852, 4151.282227, 4157.94873, 4147.179688, 4148.205078, 4157.436035, 4148.205078, 4130.769043, 4123.589844, 4123.077148, 4121.538574, 4120.0, 4120.0, 4123.077148, 4124.102539, 4122.05127, 4128.717773, 4135.384766, 4130.256348, 4124.615234, 4124.102539, 4122.563965, 4120.512695, 4117.436035, 4113.846191, 4117.436035, 4124.102539, 4118.974121, 4107.692383, 4109.743652, 4116.922852, 4112.307617, 4106.153809, 4105.641113, 4108.205078, 4111.794922, 4108.205078, 4102.563965, 4103.589844, 4097.436035, 4093.333252, 4114.871582, 4135.897461, 4133.333496, 4128.717773, 4132.820313, 4136.922852, 4131.794922, 4121.538574, 4124.615234, 4135.897461, 4140.512695, 4138.974121, 4137.436035, 4132.820313, 4126.153809, 4123.589844, 4122.563965, 4120.512695, 4123.589844, 4128.205078, 4126.153809, 4126.153809, 4132.820313, 4135.897461, 4134.871582, 4136.922852, 4137.436035, 4136.922852, 4139.487305, 4136.410156, 4135.384766, 4136.922852, 4135.897461, 4137.436035, 4142.563965, 4135.897461, 4125.128418, 4129.743652, 4136.410156, 4135.897461, 4135.384766, 4129.230957, 4118.461426, 4115.897461, 4123.589844, 4124.102539, 4120.0, 4125.641113, 4136.410156, 4145.641113, 4152.307617, 4148.205078, 4137.94873, 4142.05127, 4153.846191, 4152.307617, 4137.436035, 4125.641113, 4129.230957, 4140.0, 4138.461426, 4135.897461, 4145.128418, 4149.230957, 4139.487305, 4133.846191, 4138.974121, 4138.974121, 4134.358887, 4133.846191, 4135.897461, 4136.410156, 4137.436035, 4136.410156, 4135.384766, 4142.563965, 4150.256348, 4150.256348, 4149.230957, 4151.282227, 4150.256348, 4152.820313, 4158.461426, 4155.384766, 4153.846191, 4155.897461, 4153.333496, 4151.794922, 4155.384766, 4154.871582, 4150.256348, 4151.282227, 4153.333496, 4154.358887, 4153.846191, 4150.769043, 4149.230957, 4153.333496, 4152.307617, 4140.512695, 4142.563965, 4152.307617, 4146.666504, 4140.0, 4143.589844, 4140.512695, 4134.871582, 4136.922852, 4137.436035, 4136.410156, 4138.461426, 4137.94873, 4136.410156, 4138.974121, 4137.94873, 4125.641113, 4124.615234, 4139.487305, 4143.589844, 4135.384766, 4131.282227, 4128.205078, 4123.077148, 4126.153809, 4132.820313, 4135.384766, 4137.94873, 4142.05127, 4140.0, 4133.846191, 4135.384766, 4138.974121, 4138.974121, 4137.94873, 4143.589844, 4149.230957, 4145.128418, 4136.410156, 4130.256348, 4125.641113, 4122.05127, 4123.077148, 4125.128418, 4122.563965, 4115.384766, 4111.794922, 4115.384766, 4121.538574, 4122.05127, 4111.282227, 4108.717773, 4120.512695, 4125.128418, 4118.974121, 4118.974121, 4124.102539, 4123.077148, 4120.0, 4122.563965, 4125.641113, 4124.102539, 4121.025879, 4121.538574, 4125.128418, 4129.743652, 4124.615234, 4117.436035, 4118.461426, 4115.384766]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Veriyi temizleme\n",
        "merged_data_cleaned = merged_data.dropna()  # Eksik verileri kaldırma\n"
      ],
      "metadata": {
        "id": "aEmmwhESQ4ou"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XNdgoQVERP30"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# user_id, Timestamp, source_file sütunlarını kaldırma\n",
        "merged_data_cleaned = merged_data.drop(columns=['user_id', 'Timestamp', 'source_file'])\n",
        "\n",
        "# Veriyi ekrana yazdırma\n",
        "print(merged_data_cleaned.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3TNKe6xRP1l",
        "outputId": "9078dd01-a783-4460-a84a-2885fd5d402e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             EEG.AF3  \\\n",
            "0  [4018.461426, 4014.871826, 4011.794922, 4010.2...   \n",
            "1  [3984.615479, 3990.256348, 3988.205078, 3980.5...   \n",
            "2  [3985.641113, 3987.692383, 3985.641113, 3985.6...   \n",
            "3  [4014.358887, 4011.794922, 4015.897461, 4015.3...   \n",
            "4  [3727.692383, 3735.384521, 3740.512939, 3735.3...   \n",
            "\n",
            "                                              EEG.F7  \\\n",
            "0  [4269.230957, 4261.538574, 4252.820313, 4247.1...   \n",
            "1  [4274.358887, 4278.974121, 4270.769043, 4263.5...   \n",
            "2  [4320.512695, 4320.0, 4327.692383, 4338.974121...   \n",
            "3  [4216.410156, 4220.0, 4234.871582, 4243.589844...   \n",
            "4  [4250.769043, 4256.922852, 4252.820313, 4249.2...   \n",
            "\n",
            "                                              EEG.F3  \\\n",
            "0  [3793.846191, 3794.358887, 3788.205078, 3785.1...   \n",
            "1  [3747.692383, 3749.230713, 3746.666748, 3740.5...   \n",
            "2  [3793.333252, 3796.923096, 3794.871826, 3794.8...   \n",
            "3  [3769.230713, 3772.307617, 3775.897461, 3771.7...   \n",
            "4  [3791.281982, 3800.0, 3805.641113, 3796.410156...   \n",
            "\n",
            "                                             EEG.FC5  \\\n",
            "0  [4104.615234, 4103.589844, 4102.563965, 4101.5...   \n",
            "1  [4115.384766, 4115.897461, 4114.358887, 4112.3...   \n",
            "2  [4109.743652, 4111.282227, 4107.179688, 4108.7...   \n",
            "3  [4129.230957, 4129.230957, 4132.820313, 4132.8...   \n",
            "4  [4119.487305, 4115.897461, 4113.846191, 4118.9...   \n",
            "\n",
            "                                              EEG.T7  \\\n",
            "0  [4106.153809, 4102.05127, 4101.538574, 4102.56...   \n",
            "1  [4078.461426, 4075.897461, 4073.333252, 4075.8...   \n",
            "2  [4076.410156, 4071.794922, 4066.153809, 4068.7...   \n",
            "3  [4092.307617, 4097.94873, 4101.538574, 4098.46...   \n",
            "4  [4082.05127, 4084.615479, 4085.641113, 4087.17...   \n",
            "\n",
            "                                              EEG.P7  \\\n",
            "0  [4095.384521, 4093.846191, 4093.333252, 4091.2...   \n",
            "1  [4151.794922, 4155.384766, 4155.384766, 4155.3...   \n",
            "2  [4122.563965, 4124.102539, 4116.410156, 4115.3...   \n",
            "3  [4120.512695, 4125.641113, 4140.0, 4140.0, 413...   \n",
            "4  [4150.256348, 4152.820313, 4155.384766, 4155.8...   \n",
            "\n",
            "                                              EEG.O1  \\\n",
            "0  [4060.512939, 4066.153809, 4063.076904, 4061.0...   \n",
            "1  [4024.102539, 4032.820557, 4033.846191, 4030.7...   \n",
            "2  [4010.256348, 4021.025635, 4018.461426, 4019.4...   \n",
            "3  [4154.358887, 4152.307617, 4164.102539, 4163.5...   \n",
            "4  [4177.436035, 4180.0, 4182.563965, 4186.153809...   \n",
            "\n",
            "                                              EEG.O2  \\\n",
            "0  [4052.307617, 4056.410156, 4068.205078, 4078.4...   \n",
            "1  [4081.025635, 4090.256348, 4090.769287, 4089.7...   \n",
            "2  [4023.589844, 4032.307617, 4029.230713, 4027.1...   \n",
            "3  [4055.384521, 4048.205078, 4051.281982, 4050.7...   \n",
            "4  [4072.820557, 4076.923096, 4075.384521, 4072.8...   \n",
            "\n",
            "                                              EEG.P8  \\\n",
            "0  [3903.589844, 3906.153809, 3914.871826, 3932.3...   \n",
            "1  [3986.153809, 3991.281982, 3991.281982, 3978.4...   \n",
            "2  [3890.769287, 3900.512939, 3892.307617, 3890.2...   \n",
            "3  [3947.692383, 3943.076904, 3951.794922, 3951.2...   \n",
            "4  [3934.358887, 3947.692383, 3946.153809, 3939.4...   \n",
            "\n",
            "                                              EEG.T8  \\\n",
            "0  [4510.256348, 4512.307617, 4526.153809, 4533.3...   \n",
            "1  [4533.333496, 4540.512695, 4558.461426, 4558.4...   \n",
            "2  [4539.487305, 4545.641113, 4537.94873, 4530.76...   \n",
            "3  [4518.974121, 4508.717773, 4513.846191, 4516.9...   \n",
            "4  [4572.307617, 4568.205078, 4566.666504, 4581.5...   \n",
            "\n",
            "                                             EEG.FC6  \\\n",
            "0  [4497.436035, 4454.871582, 4456.922852, 4505.1...   \n",
            "1  [4477.94873, 4486.666504, 4486.153809, 4477.94...   \n",
            "2  [4504.615234, 4506.666504, 4497.94873, 4495.38...   \n",
            "3  [4457.94873, 4455.384766, 4464.102539, 4466.15...   \n",
            "4  [4444.102539, 4448.717773, 4453.333496, 4456.4...   \n",
            "\n",
            "                                              EEG.F4  \\\n",
            "0  [4372.820313, 4371.282227, 4365.641113, 4367.1...   \n",
            "1  [4586.153809, 4589.230957, 4590.769043, 4589.7...   \n",
            "2  [4569.230957, 4573.333496, 4563.077148, 4561.5...   \n",
            "3  [4506.153809, 4507.692383, 4514.871582, 4513.3...   \n",
            "4  [4548.205078, 4552.307617, 4556.922852, 4556.9...   \n",
            "\n",
            "                                              EEG.F8  \\\n",
            "0  [4113.333496, 4106.666504, 4104.615234, 4111.7...   \n",
            "1  [4062.564209, 4072.307617, 4069.743652, 4063.0...   \n",
            "2  [4026.666748, 4009.743652, 3996.923096, 3985.6...   \n",
            "3  [4121.538574, 4121.025879, 4125.641113, 4125.6...   \n",
            "4  [4138.461426, 4137.94873, 4140.512695, 4150.25...   \n",
            "\n",
            "                                             EEG.AF4 aro val  \n",
            "0  [4636.410156, 4592.307617, 4599.487305, 4643.5...   0   1  \n",
            "1  [4658.974121, 4671.794922, 4672.820313, 4665.1...   1   0  \n",
            "2  [4597.94873, 4599.487305, 4585.641113, 4581.53...   1   1  \n",
            "3  [4617.94873, 4613.846191, 4625.128418, 4626.15...   1   0  \n",
            "4  [4593.846191, 4598.461426, 4612.820313, 4615.3...   0   1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 283. satırdaki verilere ulaşmak için\n",
        "print(merged_data_cleaned.iloc[283])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29TQLoxCTXBo",
        "outputId": "996f2229-27b5-4754-a0dc-e37e018765f8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EEG.AF3    [3981.538574, 3987.692383, 3994.358887, 3991.7...\n",
            "EEG.F7     [4275.897461, 4282.05127, 4288.205078, 4286.15...\n",
            "EEG.F3     [3772.820557, 3771.794922, 3770.769287, 3769.2...\n",
            "EEG.FC5    [4145.128418, 4142.563965, 4143.077148, 4144.6...\n",
            "EEG.T7     [4103.077148, 4098.974121, 4095.897461, 4092.8...\n",
            "EEG.P7     [4214.358887, 4214.358887, 4218.974121, 4211.2...\n",
            "EEG.O1     [4124.102539, 4132.820313, 4131.794922, 4122.0...\n",
            "EEG.O2     [4109.743652, 4110.769043, 4111.282227, 4106.1...\n",
            "EEG.P8     [3929.743652, 3924.615479, 3926.666748, 3933.8...\n",
            "EEG.T8     [4559.487305, 4553.846191, 4569.230957, 4570.2...\n",
            "EEG.FC6    [4478.974121, 4475.384766, 4477.436035, 4477.9...\n",
            "EEG.F4     [4565.128418, 4565.128418, 4567.179688, 4561.5...\n",
            "EEG.F8     [4104.615234, 4105.128418, 4108.205078, 4106.1...\n",
            "EEG.AF4    [4583.077148, 4577.94873, 4575.897461, 4574.87...\n",
            "aro                                                        1\n",
            "val                                                        0\n",
            "Name: 283, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# merged_data veri çerçevesinin sütun isimlerini yazdırma\n",
        "print(\"Sütun İsimleri:\")\n",
        "for column in merged_data.columns:\n",
        "    print(column)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXx1aaThszbc",
        "outputId": "1f0e3d28-6676-472c-a8ab-fc72a8945779"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sütun İsimleri:\n",
            "user_id\n",
            "Timestamp\n",
            "EEG.AF3\n",
            "EEG.F7\n",
            "EEG.F3\n",
            "EEG.FC5\n",
            "EEG.T7\n",
            "EEG.P7\n",
            "EEG.O1\n",
            "EEG.O2\n",
            "EEG.P8\n",
            "EEG.T8\n",
            "EEG.FC6\n",
            "EEG.F4\n",
            "EEG.F8\n",
            "EEG.AF4\n",
            "source_file\n",
            "aro\n",
            "val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EEG ile başlayan sütunları seçme\n",
        "eeg_columns = [col for col in merged_data.columns if col.startswith('EEG.')]\n",
        "\n",
        "# EEG sütunlarındaki array'lerde kaç veri olduğunu yazdırma\n",
        "for col in eeg_columns:\n",
        "    # Her bir sütundaki array'in boyutunu yazdırma\n",
        "    print(f\"{col}: {len(merged_data[col].iloc[0])} verisi var.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uudbZNhXAro9",
        "outputId": "ff6a19cf-b1ec-4249-f116-27b10b0907e7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EEG.AF3: 3708 verisi var.\n",
            "EEG.F7: 3708 verisi var.\n",
            "EEG.F3: 3708 verisi var.\n",
            "EEG.FC5: 3708 verisi var.\n",
            "EEG.T7: 3708 verisi var.\n",
            "EEG.P7: 3708 verisi var.\n",
            "EEG.O1: 3708 verisi var.\n",
            "EEG.O2: 3708 verisi var.\n",
            "EEG.P8: 3708 verisi var.\n",
            "EEG.T8: 3708 verisi var.\n",
            "EEG.FC6: 3708 verisi var.\n",
            "EEG.F4: 3708 verisi var.\n",
            "EEG.F8: 3708 verisi var.\n",
            "EEG.AF4: 3708 verisi var.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EEG ile başlayan sütunları seçme\n",
        "eeg_columns = [col for col in merged_data.columns if col.startswith('EEG.')]\n",
        "\n",
        "# EEG sütunlarındaki array'lerdeki uzunlukları kontrol etme\n",
        "for col in eeg_columns:\n",
        "    inconsistent_rows = []\n",
        "\n",
        "    # Her bir satırdaki array'in uzunluğunu kontrol etme\n",
        "    for index, row in merged_data.iterrows():\n",
        "        if len(row[col]) != len(merged_data[col].iloc[0]):\n",
        "            inconsistent_rows.append(index)\n",
        "\n",
        "    # Eğer tutarsızlık varsa, bu satırları yazdırma\n",
        "    if inconsistent_rows:\n",
        "        print(f\"Farklı uzunlukta array bulunan satırlar ({col} sütununda): {inconsistent_rows}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI4XG0OzA1dO",
        "outputId": "d19af705-315e-48bb-9cfa-300eefff08fc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Farklı uzunlukta array bulunan satırlar (EEG.AF3 sütununda): [2, 4, 5, 6, 9, 12, 13, 16, 22, 23, 24, 25, 28, 32, 33, 34, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 79, 85, 86, 87, 88, 89, 90, 91, 92, 99, 100, 101, 108, 109, 110, 111, 112, 119, 120, 121, 122, 123, 128, 129, 130, 131, 132, 133, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 180, 181, 184, 187, 188, 189, 190, 191, 192, 193, 194, 200, 201, 202, 203, 204, 205, 206, 216, 217, 218, 219, 220, 221, 222, 223, 225, 230, 231, 239, 242, 248, 249, 250, 251, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 278, 279, 280, 281, 282, 283, 284, 292, 293, 294, 295, 296, 297, 298, 299, 300, 303, 304, 305, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 386, 388, 389, 390, 391, 392, 393, 394, 395, 400, 401, 402, 403, 404, 405, 412, 413, 414, 415, 416, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 436, 437, 438, 439, 444, 445, 446, 447, 448, 449, 453, 454, 455, 456, 457, 458, 459, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 482, 484, 486, 487, 488, 489, 496, 497, 498, 499, 501, 503, 504, 517, 524, 525, 526, 527, 528, 529, 530, 531, 536, 537, 538, 539, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 559, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 579, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 600, 601, 602, 603, 612, 613, 614, 615, 616, 617, 618, 619, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 639, 644, 645, 646, 647, 652, 653, 654, 655, 656, 657, 658, 661, 662, 663, 664, 665, 666, 667, 668, 669, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 733, 734, 735, 736, 737, 738, 739, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 759, 760, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 784, 785, 786, 787, 788, 789, 790, 791, 799]\n",
            "Farklı uzunlukta array bulunan satırlar (EEG.F7 sütununda): [2, 4, 5, 6, 9, 12, 13, 16, 22, 23, 24, 25, 28, 32, 33, 34, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 79, 85, 86, 87, 88, 89, 90, 91, 92, 99, 100, 101, 108, 109, 110, 111, 112, 119, 120, 121, 122, 123, 128, 129, 130, 131, 132, 133, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 180, 181, 184, 187, 188, 189, 190, 191, 192, 193, 194, 200, 201, 202, 203, 204, 205, 206, 216, 217, 218, 219, 220, 221, 222, 223, 225, 230, 231, 239, 242, 248, 249, 250, 251, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 278, 279, 280, 281, 282, 283, 284, 292, 293, 294, 295, 296, 297, 298, 299, 300, 303, 304, 305, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 386, 388, 389, 390, 391, 392, 393, 394, 395, 400, 401, 402, 403, 404, 405, 412, 413, 414, 415, 416, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 436, 437, 438, 439, 444, 445, 446, 447, 448, 449, 453, 454, 455, 456, 457, 458, 459, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 482, 484, 486, 487, 488, 489, 496, 497, 498, 499, 501, 503, 504, 517, 524, 525, 526, 527, 528, 529, 530, 531, 536, 537, 538, 539, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 559, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 579, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 600, 601, 602, 603, 612, 613, 614, 615, 616, 617, 618, 619, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 639, 644, 645, 646, 647, 652, 653, 654, 655, 656, 657, 658, 661, 662, 663, 664, 665, 666, 667, 668, 669, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 733, 734, 735, 736, 737, 738, 739, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 759, 760, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 784, 785, 786, 787, 788, 789, 790, 791, 799]\n",
            "Farklı uzunlukta array bulunan satırlar (EEG.F3 sütununda): [2, 4, 5, 6, 9, 12, 13, 16, 22, 23, 24, 25, 28, 32, 33, 34, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 79, 85, 86, 87, 88, 89, 90, 91, 92, 99, 100, 101, 108, 109, 110, 111, 112, 119, 120, 121, 122, 123, 128, 129, 130, 131, 132, 133, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 180, 181, 184, 187, 188, 189, 190, 191, 192, 193, 194, 200, 201, 202, 203, 204, 205, 206, 216, 217, 218, 219, 220, 221, 222, 223, 225, 230, 231, 239, 242, 248, 249, 250, 251, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 278, 279, 280, 281, 282, 283, 284, 292, 293, 294, 295, 296, 297, 298, 299, 300, 303, 304, 305, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 386, 388, 389, 390, 391, 392, 393, 394, 395, 400, 401, 402, 403, 404, 405, 412, 413, 414, 415, 416, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 436, 437, 438, 439, 444, 445, 446, 447, 448, 449, 453, 454, 455, 456, 457, 458, 459, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 482, 484, 486, 487, 488, 489, 496, 497, 498, 499, 501, 503, 504, 517, 524, 525, 526, 527, 528, 529, 530, 531, 536, 537, 538, 539, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 559, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 579, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 600, 601, 602, 603, 612, 613, 614, 615, 616, 617, 618, 619, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 639, 644, 645, 646, 647, 652, 653, 654, 655, 656, 657, 658, 661, 662, 663, 664, 665, 666, 667, 668, 669, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 733, 734, 735, 736, 737, 738, 739, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 759, 760, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 784, 785, 786, 787, 788, 789, 790, 791, 799]\n",
            "Farklı uzunlukta array bulunan satırlar (EEG.FC5 sütununda): [2, 4, 5, 6, 9, 12, 13, 16, 22, 23, 24, 25, 28, 32, 33, 34, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 79, 85, 86, 87, 88, 89, 90, 91, 92, 99, 100, 101, 108, 109, 110, 111, 112, 119, 120, 121, 122, 123, 128, 129, 130, 131, 132, 133, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 180, 181, 184, 187, 188, 189, 190, 191, 192, 193, 194, 200, 201, 202, 203, 204, 205, 206, 216, 217, 218, 219, 220, 221, 222, 223, 225, 230, 231, 239, 242, 248, 249, 250, 251, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 278, 279, 280, 281, 282, 283, 284, 292, 293, 294, 295, 296, 297, 298, 299, 300, 303, 304, 305, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 386, 388, 389, 390, 391, 392, 393, 394, 395, 400, 401, 402, 403, 404, 405, 412, 413, 414, 415, 416, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 436, 437, 438, 439, 444, 445, 446, 447, 448, 449, 453, 454, 455, 456, 457, 458, 459, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 482, 484, 486, 487, 488, 489, 496, 497, 498, 499, 501, 503, 504, 517, 524, 525, 526, 527, 528, 529, 530, 531, 536, 537, 538, 539, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 559, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 579, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 600, 601, 602, 603, 612, 613, 614, 615, 616, 617, 618, 619, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 639, 644, 645, 646, 647, 652, 653, 654, 655, 656, 657, 658, 661, 662, 663, 664, 665, 666, 667, 668, 669, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 733, 734, 735, 736, 737, 738, 739, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 759, 760, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 784, 785, 786, 787, 788, 789, 790, 791, 799]\n",
            "Farklı uzunlukta array bulunan satırlar (EEG.T7 sütununda): [2, 4, 5, 6, 9, 12, 13, 16, 22, 23, 24, 25, 28, 32, 33, 34, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 79, 85, 86, 87, 88, 89, 90, 91, 92, 99, 100, 101, 108, 109, 110, 111, 112, 119, 120, 121, 122, 123, 128, 129, 130, 131, 132, 133, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 180, 181, 184, 187, 188, 189, 190, 191, 192, 193, 194, 200, 201, 202, 203, 204, 205, 206, 216, 217, 218, 219, 220, 221, 222, 223, 225, 230, 231, 239, 242, 248, 249, 250, 251, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 278, 279, 280, 281, 282, 283, 284, 292, 293, 294, 295, 296, 297, 298, 299, 300, 303, 304, 305, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 386, 388, 389, 390, 391, 392, 393, 394, 395, 400, 401, 402, 403, 404, 405, 412, 413, 414, 415, 416, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 436, 437, 438, 439, 444, 445, 446, 447, 448, 449, 453, 454, 455, 456, 457, 458, 459, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 482, 484, 486, 487, 488, 489, 496, 497, 498, 499, 501, 503, 504, 517, 524, 525, 526, 527, 528, 529, 530, 531, 536, 537, 538, 539, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 559, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 579, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 600, 601, 602, 603, 612, 613, 614, 615, 616, 617, 618, 619, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 639, 644, 645, 646, 647, 652, 653, 654, 655, 656, 657, 658, 661, 662, 663, 664, 665, 666, 667, 668, 669, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 733, 734, 735, 736, 737, 738, 739, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 759, 760, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 784, 785, 786, 787, 788, 789, 790, 791, 799]\n",
            "Farklı uzunlukta array bulunan satırlar (EEG.P7 sütununda): [2, 4, 5, 6, 9, 12, 13, 16, 22, 23, 24, 25, 28, 32, 33, 34, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 79, 85, 86, 87, 88, 89, 90, 91, 92, 99, 100, 101, 108, 109, 110, 111, 112, 119, 120, 121, 122, 123, 128, 129, 130, 131, 132, 133, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 180, 181, 184, 187, 188, 189, 190, 191, 192, 193, 194, 200, 201, 202, 203, 204, 205, 206, 216, 217, 218, 219, 220, 221, 222, 223, 225, 230, 231, 239, 242, 248, 249, 250, 251, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 278, 279, 280, 281, 282, 283, 284, 292, 293, 294, 295, 296, 297, 298, 299, 300, 303, 304, 305, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 386, 388, 389, 390, 391, 392, 393, 394, 395, 400, 401, 402, 403, 404, 405, 412, 413, 414, 415, 416, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 436, 437, 438, 439, 444, 445, 446, 447, 448, 449, 453, 454, 455, 456, 457, 458, 459, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 482, 484, 486, 487, 488, 489, 496, 497, 498, 499, 501, 503, 504, 517, 524, 525, 526, 527, 528, 529, 530, 531, 536, 537, 538, 539, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 559, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 579, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 600, 601, 602, 603, 612, 613, 614, 615, 616, 617, 618, 619, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 639, 644, 645, 646, 647, 652, 653, 654, 655, 656, 657, 658, 661, 662, 663, 664, 665, 666, 667, 668, 669, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 733, 734, 735, 736, 737, 738, 739, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 759, 760, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 784, 785, 786, 787, 788, 789, 790, 791, 799]\n",
            "Farklı uzunlukta array bulunan satırlar (EEG.O1 sütununda): [2, 4, 5, 6, 9, 12, 13, 16, 22, 23, 24, 25, 28, 32, 33, 34, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 79, 85, 86, 87, 88, 89, 90, 91, 92, 99, 100, 101, 108, 109, 110, 111, 112, 119, 120, 121, 122, 123, 128, 129, 130, 131, 132, 133, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 180, 181, 184, 187, 188, 189, 190, 191, 192, 193, 194, 200, 201, 202, 203, 204, 205, 206, 216, 217, 218, 219, 220, 221, 222, 223, 225, 230, 231, 239, 242, 248, 249, 250, 251, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 278, 279, 280, 281, 282, 283, 284, 292, 293, 294, 295, 296, 297, 298, 299, 300, 303, 304, 305, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 386, 388, 389, 390, 391, 392, 393, 394, 395, 400, 401, 402, 403, 404, 405, 412, 413, 414, 415, 416, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 436, 437, 438, 439, 444, 445, 446, 447, 448, 449, 453, 454, 455, 456, 457, 458, 459, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 482, 484, 486, 487, 488, 489, 496, 497, 498, 499, 501, 503, 504, 517, 524, 525, 526, 527, 528, 529, 530, 531, 536, 537, 538, 539, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 559, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 579, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 600, 601, 602, 603, 612, 613, 614, 615, 616, 617, 618, 619, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 639, 644, 645, 646, 647, 652, 653, 654, 655, 656, 657, 658, 661, 662, 663, 664, 665, 666, 667, 668, 669, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 733, 734, 735, 736, 737, 738, 739, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 759, 760, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 784, 785, 786, 787, 788, 789, 790, 791, 799]\n",
            "Farklı uzunlukta array bulunan satırlar (EEG.O2 sütununda): [2, 4, 5, 6, 9, 12, 13, 16, 22, 23, 24, 25, 28, 32, 33, 34, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 79, 85, 86, 87, 88, 89, 90, 91, 92, 99, 100, 101, 108, 109, 110, 111, 112, 119, 120, 121, 122, 123, 128, 129, 130, 131, 132, 133, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 180, 181, 184, 187, 188, 189, 190, 191, 192, 193, 194, 200, 201, 202, 203, 204, 205, 206, 216, 217, 218, 219, 220, 221, 222, 223, 225, 230, 231, 239, 242, 248, 249, 250, 251, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 278, 279, 280, 281, 282, 283, 284, 292, 293, 294, 295, 296, 297, 298, 299, 300, 303, 304, 305, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 386, 388, 389, 390, 391, 392, 393, 394, 395, 400, 401, 402, 403, 404, 405, 412, 413, 414, 415, 416, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 436, 437, 438, 439, 444, 445, 446, 447, 448, 449, 453, 454, 455, 456, 457, 458, 459, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 482, 484, 486, 487, 488, 489, 496, 497, 498, 499, 501, 503, 504, 517, 524, 525, 526, 527, 528, 529, 530, 531, 536, 537, 538, 539, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 559, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 579, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 600, 601, 602, 603, 612, 613, 614, 615, 616, 617, 618, 619, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 639, 644, 645, 646, 647, 652, 653, 654, 655, 656, 657, 658, 661, 662, 663, 664, 665, 666, 667, 668, 669, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 733, 734, 735, 736, 737, 738, 739, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 759, 760, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 784, 785, 786, 787, 788, 789, 790, 791, 799]\n",
            "Farklı uzunlukta array bulunan satırlar (EEG.P8 sütununda): [2, 4, 5, 6, 9, 12, 13, 16, 22, 23, 24, 25, 28, 32, 33, 34, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 79, 85, 86, 87, 88, 89, 90, 91, 92, 99, 100, 101, 108, 109, 110, 111, 112, 119, 120, 121, 122, 123, 128, 129, 130, 131, 132, 133, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 180, 181, 184, 187, 188, 189, 190, 191, 192, 193, 194, 200, 201, 202, 203, 204, 205, 206, 216, 217, 218, 219, 220, 221, 222, 223, 225, 230, 231, 239, 242, 248, 249, 250, 251, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 278, 279, 280, 281, 282, 283, 284, 292, 293, 294, 295, 296, 297, 298, 299, 300, 303, 304, 305, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 386, 388, 389, 390, 391, 392, 393, 394, 395, 400, 401, 402, 403, 404, 405, 412, 413, 414, 415, 416, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 436, 437, 438, 439, 444, 445, 446, 447, 448, 449, 453, 454, 455, 456, 457, 458, 459, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 482, 484, 486, 487, 488, 489, 496, 497, 498, 499, 501, 503, 504, 517, 524, 525, 526, 527, 528, 529, 530, 531, 536, 537, 538, 539, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 559, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 579, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 600, 601, 602, 603, 612, 613, 614, 615, 616, 617, 618, 619, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 639, 644, 645, 646, 647, 652, 653, 654, 655, 656, 657, 658, 661, 662, 663, 664, 665, 666, 667, 668, 669, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 733, 734, 735, 736, 737, 738, 739, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 759, 760, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 784, 785, 786, 787, 788, 789, 790, 791, 799]\n",
            "Farklı uzunlukta array bulunan satırlar (EEG.T8 sütununda): [2, 4, 5, 6, 9, 12, 13, 16, 22, 23, 24, 25, 28, 32, 33, 34, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 79, 85, 86, 87, 88, 89, 90, 91, 92, 99, 100, 101, 108, 109, 110, 111, 112, 119, 120, 121, 122, 123, 128, 129, 130, 131, 132, 133, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 180, 181, 184, 187, 188, 189, 190, 191, 192, 193, 194, 200, 201, 202, 203, 204, 205, 206, 216, 217, 218, 219, 220, 221, 222, 223, 225, 230, 231, 239, 242, 248, 249, 250, 251, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 278, 279, 280, 281, 282, 283, 284, 292, 293, 294, 295, 296, 297, 298, 299, 300, 303, 304, 305, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 386, 388, 389, 390, 391, 392, 393, 394, 395, 400, 401, 402, 403, 404, 405, 412, 413, 414, 415, 416, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 436, 437, 438, 439, 444, 445, 446, 447, 448, 449, 453, 454, 455, 456, 457, 458, 459, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 482, 484, 486, 487, 488, 489, 496, 497, 498, 499, 501, 503, 504, 517, 524, 525, 526, 527, 528, 529, 530, 531, 536, 537, 538, 539, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 559, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 579, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 600, 601, 602, 603, 612, 613, 614, 615, 616, 617, 618, 619, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 639, 644, 645, 646, 647, 652, 653, 654, 655, 656, 657, 658, 661, 662, 663, 664, 665, 666, 667, 668, 669, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 733, 734, 735, 736, 737, 738, 739, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 759, 760, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 784, 785, 786, 787, 788, 789, 790, 791, 799]\n",
            "Farklı uzunlukta array bulunan satırlar (EEG.FC6 sütununda): [2, 4, 5, 6, 9, 12, 13, 16, 22, 23, 24, 25, 28, 32, 33, 34, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 79, 85, 86, 87, 88, 89, 90, 91, 92, 99, 100, 101, 108, 109, 110, 111, 112, 119, 120, 121, 122, 123, 128, 129, 130, 131, 132, 133, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 180, 181, 184, 187, 188, 189, 190, 191, 192, 193, 194, 200, 201, 202, 203, 204, 205, 206, 216, 217, 218, 219, 220, 221, 222, 223, 225, 230, 231, 239, 242, 248, 249, 250, 251, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 278, 279, 280, 281, 282, 283, 284, 292, 293, 294, 295, 296, 297, 298, 299, 300, 303, 304, 305, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 386, 388, 389, 390, 391, 392, 393, 394, 395, 400, 401, 402, 403, 404, 405, 412, 413, 414, 415, 416, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 436, 437, 438, 439, 444, 445, 446, 447, 448, 449, 453, 454, 455, 456, 457, 458, 459, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 482, 484, 486, 487, 488, 489, 496, 497, 498, 499, 501, 503, 504, 517, 524, 525, 526, 527, 528, 529, 530, 531, 536, 537, 538, 539, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 559, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 579, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 600, 601, 602, 603, 612, 613, 614, 615, 616, 617, 618, 619, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 639, 644, 645, 646, 647, 652, 653, 654, 655, 656, 657, 658, 661, 662, 663, 664, 665, 666, 667, 668, 669, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 733, 734, 735, 736, 737, 738, 739, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 759, 760, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 784, 785, 786, 787, 788, 789, 790, 791, 799]\n",
            "Farklı uzunlukta array bulunan satırlar (EEG.F4 sütununda): [2, 4, 5, 6, 9, 12, 13, 16, 22, 23, 24, 25, 28, 32, 33, 34, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 79, 85, 86, 87, 88, 89, 90, 91, 92, 99, 100, 101, 108, 109, 110, 111, 112, 119, 120, 121, 122, 123, 128, 129, 130, 131, 132, 133, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 180, 181, 184, 187, 188, 189, 190, 191, 192, 193, 194, 200, 201, 202, 203, 204, 205, 206, 216, 217, 218, 219, 220, 221, 222, 223, 225, 230, 231, 239, 242, 248, 249, 250, 251, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 278, 279, 280, 281, 282, 283, 284, 292, 293, 294, 295, 296, 297, 298, 299, 300, 303, 304, 305, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 386, 388, 389, 390, 391, 392, 393, 394, 395, 400, 401, 402, 403, 404, 405, 412, 413, 414, 415, 416, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 436, 437, 438, 439, 444, 445, 446, 447, 448, 449, 453, 454, 455, 456, 457, 458, 459, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 482, 484, 486, 487, 488, 489, 496, 497, 498, 499, 501, 503, 504, 517, 524, 525, 526, 527, 528, 529, 530, 531, 536, 537, 538, 539, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 559, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 579, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 600, 601, 602, 603, 612, 613, 614, 615, 616, 617, 618, 619, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 639, 644, 645, 646, 647, 652, 653, 654, 655, 656, 657, 658, 661, 662, 663, 664, 665, 666, 667, 668, 669, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 733, 734, 735, 736, 737, 738, 739, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 759, 760, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 784, 785, 786, 787, 788, 789, 790, 791, 799]\n",
            "Farklı uzunlukta array bulunan satırlar (EEG.F8 sütununda): [2, 4, 5, 6, 9, 12, 13, 16, 22, 23, 24, 25, 28, 32, 33, 34, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 79, 85, 86, 87, 88, 89, 90, 91, 92, 99, 100, 101, 108, 109, 110, 111, 112, 119, 120, 121, 122, 123, 128, 129, 130, 131, 132, 133, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 180, 181, 184, 187, 188, 189, 190, 191, 192, 193, 194, 200, 201, 202, 203, 204, 205, 206, 216, 217, 218, 219, 220, 221, 222, 223, 225, 230, 231, 239, 242, 248, 249, 250, 251, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 278, 279, 280, 281, 282, 283, 284, 292, 293, 294, 295, 296, 297, 298, 299, 300, 303, 304, 305, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 386, 388, 389, 390, 391, 392, 393, 394, 395, 400, 401, 402, 403, 404, 405, 412, 413, 414, 415, 416, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 436, 437, 438, 439, 444, 445, 446, 447, 448, 449, 453, 454, 455, 456, 457, 458, 459, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 482, 484, 486, 487, 488, 489, 496, 497, 498, 499, 501, 503, 504, 517, 524, 525, 526, 527, 528, 529, 530, 531, 536, 537, 538, 539, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 559, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 579, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 600, 601, 602, 603, 612, 613, 614, 615, 616, 617, 618, 619, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 639, 644, 645, 646, 647, 652, 653, 654, 655, 656, 657, 658, 661, 662, 663, 664, 665, 666, 667, 668, 669, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 733, 734, 735, 736, 737, 738, 739, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 759, 760, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 784, 785, 786, 787, 788, 789, 790, 791, 799]\n",
            "Farklı uzunlukta array bulunan satırlar (EEG.AF4 sütununda): [2, 4, 5, 6, 9, 12, 13, 16, 22, 23, 24, 25, 28, 32, 33, 34, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 79, 85, 86, 87, 88, 89, 90, 91, 92, 99, 100, 101, 108, 109, 110, 111, 112, 119, 120, 121, 122, 123, 128, 129, 130, 131, 132, 133, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 180, 181, 184, 187, 188, 189, 190, 191, 192, 193, 194, 200, 201, 202, 203, 204, 205, 206, 216, 217, 218, 219, 220, 221, 222, 223, 225, 230, 231, 239, 242, 248, 249, 250, 251, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 278, 279, 280, 281, 282, 283, 284, 292, 293, 294, 295, 296, 297, 298, 299, 300, 303, 304, 305, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 386, 388, 389, 390, 391, 392, 393, 394, 395, 400, 401, 402, 403, 404, 405, 412, 413, 414, 415, 416, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 436, 437, 438, 439, 444, 445, 446, 447, 448, 449, 453, 454, 455, 456, 457, 458, 459, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 482, 484, 486, 487, 488, 489, 496, 497, 498, 499, 501, 503, 504, 517, 524, 525, 526, 527, 528, 529, 530, 531, 536, 537, 538, 539, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 559, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 579, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 600, 601, 602, 603, 612, 613, 614, 615, 616, 617, 618, 619, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 639, 644, 645, 646, 647, 652, 653, 654, 655, 656, 657, 658, 661, 662, 663, 664, 665, 666, 667, 668, 669, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 733, 734, 735, 736, 737, 738, 739, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 759, 760, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 784, 785, 786, 787, 788, 789, 790, 791, 799]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "import pandas as pd\n",
        "\n",
        "# Band-pass filtresi için butterworth filtresi oluşturma\n",
        "def bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
        "    nyquist = 0.5 * fs  # Nyquist frekansı\n",
        "    low = lowcut / nyquist  # Düşük frekans kesimi\n",
        "    high = highcut / nyquist  # Yüksek frekans kesimi\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "\n",
        "    if len(data) > order:  # Veri uzunluğunun filtreleme için yeterli olup olmadığını kontrol et\n",
        "        filtered_data = filtfilt(b, a, data)\n",
        "    else:\n",
        "        filtered_data = data  # Eğer veri çok kısa ise, filtreleme yapmadan veriyi olduğu gibi bırak\n",
        "    return filtered_data\n",
        "\n",
        "# EEG verilerini band-pass filtre uygulamak\n",
        "def filter_eeg_data(eeg_data, lowcut, highcut, fs):\n",
        "    filtered_data = {}\n",
        "    for column in eeg_data.columns:\n",
        "        # Her bir EEG kanalındaki veriyi al (bu veri dizisi olarak alınmalıdır)\n",
        "        data = eeg_data[column]  # EEG verisi zaten bir dizi olabilir\n",
        "        # Her kanal için band-pass filtresi uygulama\n",
        "        filtered_data[column] = data.apply(lambda x: bandpass_filter(x, lowcut, highcut, fs))\n",
        "    return pd.DataFrame(filtered_data)\n",
        "\n",
        "# EEG verilerinin bulunduğu 'merged_data' veri çerçevesini 'user_id' ve 'Timestamp' hariç al\n",
        "eeg_data = merged_data.drop(columns=['user_id', 'Timestamp', 'aro', 'val'])\n",
        "\n",
        "# Verinin örnek parametreleri\n",
        "lowcut = 1.0  # Düşük frekans (Hz)\n",
        "highcut = 50.0  # Yüksek frekans (Hz)\n",
        "fs = 250  # Örnekleme frekansı (Hz)\n",
        "\n",
        "# Band-pass filtresini EEG verilerine uygulama\n",
        "filtered_eeg_data = filter_eeg_data(eeg_data, lowcut, highcut, fs)\n",
        "\n",
        "# 'aro' ve 'val' sütunlarını olduğu gibi bırakıyoruz ve filtresi yapılmış EEG verileriyle birleştiriyoruz\n",
        "filtered_eeg_data['aro'] = merged_data['aro']\n",
        "filtered_eeg_data['val'] = merged_data['val']\n",
        "\n"
      ],
      "metadata": {
        "id": "oUFkqSMsYb9Q"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_eeg_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPyge3DYYb28",
        "outputId": "f55a1fed-f39b-4f50-90c5-bb0d1af73085"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             EEG.AF3  \\\n",
            "0  [3.822408254386287, -0.107609635535617, -2.136...   \n",
            "1  [-4.684884249648351, -2.0445122131796603, -3.3...   \n",
            "2  [-1.7145195955541543, -2.135729125035467, -0.8...   \n",
            "3  [3.719529942264249, 3.8973080855562907, 4.0090...   \n",
            "4  [-3.125178227921227, 3.013932457129723, 4.8534...   \n",
            "\n",
            "                                              EEG.F7  \\\n",
            "0  [15.159046022015639, 8.153032011756563, 0.6569...   \n",
            "1  [-0.6178966280137121, -1.3426158953502862, -3....   \n",
            "2  [2.7197010893899307, 5.764214948801842, 11.241...   \n",
            "3  [14.422464312746353, 23.385855481357922, 30.97...   \n",
            "4  [-4.803572018680795, -2.416309726409969, -1.99...   \n",
            "\n",
            "                                              EEG.F3  \\\n",
            "0  [5.382019274341784, 2.8269712691049156, 1.0699...   \n",
            "1  [-2.3730615932454326, -2.2196447406221522, -4....   \n",
            "2  [-2.025532518982459, -1.624470650652609, 0.195...   \n",
            "3  [0.27144962352863555, 3.9617594432407564, 5.16...   \n",
            "4  [2.666048738620909, 10.393312292786579, 12.370...   \n",
            "\n",
            "                                             EEG.FC5  \\\n",
            "0  [2.8015370842559397, 2.2803030447073542, 1.246...   \n",
            "1  [-2.4524803443820917, -2.7359528858409545, -3....   \n",
            "2  [0.09192568192889339, -1.779423071088083, -1.0...   \n",
            "3  [2.2516743972791042, 5.399336902009578, 5.5502...   \n",
            "4  [2.9098666849978074, -0.7358995751052376, -0.6...   \n",
            "\n",
            "                                              EEG.T7  \\\n",
            "0  [2.413348546238972, 0.35536092118462237, -1.46...   \n",
            "1  [-2.0301940821199973, -4.527937735696225, -5.1...   \n",
            "2  [-0.3692866749065382, -6.6213432306844755, -8....   \n",
            "3  [2.6342794286072637, 9.179651171722103, 10.672...   \n",
            "4  [1.087193868786395, 2.708783199869481, 4.94066...   \n",
            "\n",
            "                                              EEG.P7  \\\n",
            "0  [0.481805002168141, -0.4487287493472509, -1.52...   \n",
            "1  [-3.2690727472570575, -1.8775905052962396, 0.4...   \n",
            "2  [1.6728364055258687, -2.9692411063172184, -4.5...   \n",
            "3  [2.957130727411079, 13.609503086572142, 19.473...   \n",
            "4  [2.597563373136598, 5.531784985749087, 7.91383...   \n",
            "\n",
            "                                              EEG.O1  \\\n",
            "0  [1.1084215392016583, 2.4395132821823196, 3.277...   \n",
            "1  [-1.597035955122126, 4.239079872640968, 6.3856...   \n",
            "2  [-4.106608025106621, 0.12547717361949118, 3.74...   \n",
            "3  [6.415814910950556, 12.046007256956894, 14.991...   \n",
            "4  [10.71653447402178, 14.34991474027254, 17.0631...   \n",
            "\n",
            "                                              EEG.O2  \\\n",
            "0  [8.11094308779527, 15.345906030212259, 23.7189...   \n",
            "1  [0.7321843392839571, 7.324857388416966, 10.890...   \n",
            "2  [-1.913124579963054, 1.5929308254944559, 4.232...   \n",
            "3  [-0.5097067209353809, -3.499754415099878, -6.1...   \n",
            "4  [-2.3760440083115046, -0.05212338116666329, 0....   \n",
            "\n",
            "                                              EEG.P8  \\\n",
            "0  [9.476272686343986, 17.866388389386664, 26.645...   \n",
            "1  [3.597119113115049, 7.672226661507067, 4.81702...   \n",
            "2  [0.865274559198936, 1.2802453745907443, 2.3625...   \n",
            "3  [4.760175788545098, 6.059082395968099, 6.50851...   \n",
            "4  [4.253989472937165, 9.674406350051289, 13.7802...   \n",
            "\n",
            "                                              EEG.T8  \\\n",
            "0  [13.49026585748103, 22.980288943193095, 28.707...   \n",
            "1  [3.410638991630826, 17.69696404444715, 24.0854...   \n",
            "2  [-1.7152282396544454, -3.2245193451242393, -3....   \n",
            "3  [4.8453358350507685, 0.7705363253665498, -0.85...   \n",
            "4  [2.5452735958025343, -0.5513901129031591, 2.39...   \n",
            "\n",
            "                                             EEG.FC6  \\\n",
            "0  [5.478307923277345, 25.5500580476192, -23.3845...   \n",
            "1  [-1.1451612757007614, 4.002414933014902, 4.857...   \n",
            "2  [-1.4770132805307985, -5.105210753343888, -6.8...   \n",
            "3  [8.086076771946063, 11.506232311349908, 13.202...   \n",
            "4  [-2.0299685131473613, 2.838883184719753, 6.290...   \n",
            "\n",
            "                                              EEG.F4  \\\n",
            "0  [5.329633744215592, 3.901037683045259, 2.45642...   \n",
            "1  [-0.2913348730054066, 2.444050052147919, 3.491...   \n",
            "2  [0.6988276610406577, -1.9511888717454569, -2.9...   \n",
            "3  [-1.579379404861311, 3.502519839403521, 5.0518...   \n",
            "4  [-0.17076620007657273, 5.702495966899938, 8.25...   \n",
            "\n",
            "                                              EEG.F8  \\\n",
            "0  [-4.75733162304326, -8.168739616605047, -10.41...   \n",
            "1  [7.04759613641237, 11.105105458123338, 12.7401...   \n",
            "2  [-6.928818766846524, -24.193093955646013, -37....   \n",
            "3  [1.291416185755466, 3.147201735494306, 4.29590...   \n",
            "4  [-4.528788864820896, -3.093988064799788, -0.53...   \n",
            "\n",
            "                                             EEG.AF4 source_file aro val  \n",
            "0  [0.8903140333774182, 17.47909907696328, -30.27...      (1, 1)   0   1  \n",
            "1  [-0.0047344279113516186, 8.421161214988535, 11...      (1, 2)   1   0  \n",
            "2  [-2.4315752551228953, -9.674732388665703, -13....      (1, 3)   1   1  \n",
            "3  [8.282725289538257, 11.96584185221498, 13.9276...      (1, 4)   1   0  \n",
            "4  [-3.513788293108062, 4.994735487184432, 11.265...      (1, 5)   0   1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lHbkfnkDYbxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection"
      ],
      "metadata": {
        "id": "uY8MjtfIikmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_selection import mutual_info_classif"
      ],
      "metadata": {
        "id": "LZ8TXbsluM57"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "# Karşılıklı bilgi hesaplamak için fonksiyon (regresyon)\n",
        "def mutual_information(X, y):\n",
        "    \"\"\"\n",
        "    Karşılıklı bilgi hesaplama fonksiyonu (regresyon için).\n",
        "    X: Özellikler\n",
        "    y: Sürekli etiketler (regresyon için)\n",
        "    \"\"\"\n",
        "    return mutual_info_regression(X, y)\n",
        "\n",
        "# DMIM özellik seçimi için örnek fonksiyon\n",
        "def dmim_feature_selection(X, y):\n",
        "    \"\"\"\n",
        "    DMIM temelli özellik seçimi.\n",
        "    X: Özellik matrisi\n",
        "    y: Etiketler (sürekli)\n",
        "    \"\"\"\n",
        "    n_features = X.shape[1]\n",
        "    feature_scores = np.zeros(n_features)\n",
        "\n",
        "    # Her özelliği değerlendirme\n",
        "    for i in range(n_features):\n",
        "        feature = X[:, i]\n",
        "        mi_with_class = mutual_information(feature.reshape(-1, 1), y)  # MI özelliği ve sınıf\n",
        "        max_mi_with_other_features = np.max([mutual_information(feature.reshape(-1, 1), X[:, j]) for j in range(n_features) if j != i])\n",
        "        max_mi_with_class_specific = np.max([mutual_information(feature.reshape(-1, 1), X[:, j]) for j in range(n_features)])\n",
        "\n",
        "        # DMIM fonksiyonunu kullanarak her özelliği derecelendirme\n",
        "        feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
        "\n",
        "    # En yüksek skora sahip özellikleri seçme (örneğin, en iyi 20)\n",
        "    top_features_idx = np.argsort(feature_scores)[-20:]\n",
        "\n",
        "    return top_features_idx, feature_scores\n",
        "\n",
        "# Örnek EEG verisi (merged_data_cleaned)\n",
        "X = np.random.rand(100, 50)  # 100 örnek ve 50 özellik (rastgele veriler)\n",
        "y = np.random.rand(100)  # Sürekli etiketler (regresyon)\n",
        "\n",
        "# DMIM ile özellik seçimi yapma\n",
        "top_features, feature_scores = dmim_feature_selection(X, y)\n",
        "\n",
        "# Seçilen en iyi 20 özelliği gösterme\n",
        "print(\"En iyi 20 özellik:\", top_features)\n",
        "print(\"Özellik skorlari:\", feature_scores[top_features])\n",
        "\n",
        "# Özelliklerin sıralanmış hali\n",
        "print(\"Tüm özellik sıralaması:\", np.argsort(feature_scores)[::-1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AKex-J2PTlP",
        "outputId": "ecc3ec2c-c8a3-4638-bc05-b687e46f4006"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n",
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En iyi 20 özellik: [18 21 48 39 22 10  7 28  8 30 45 13 19 15 33 24 49 29 25  3]\n",
            "Özellik skorlari: [3.20373796 3.20705975 3.20705975 3.20866592 3.2107693  3.21422501\n",
            " 3.21746244 3.21971968 3.22064728 3.22064728 3.2271317  3.22721429\n",
            " 3.22748163 3.24457868 3.24702821 3.25716412 3.27660096 3.29757917\n",
            " 3.30653187 3.31250873]\n",
            "Tüm özellik sıralaması: [ 3 25 29 49 24 33 15 19 13 45 30  8 28  7 10 22 39 48 21 18 17 14 42 34\n",
            " 46 27 37 31  1 43 47 16 23  6 40  9 44 35 36  2 12 32 20  4 38 11 41  0\n",
            " 26  5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-7ae4fef85b75>:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  feature_scores[i] = mi_with_class - max_mi_with_other_features + max_mi_with_class_specific\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Özellik skoru görselleştirme\n",
        "def plot_feature_importance(feature_scores):\n",
        "    \"\"\"\n",
        "    Özelliklerin önem derecelerini gösteren bar grafiği.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(range(len(feature_scores)), feature_scores, color='skyblue')\n",
        "    plt.xlabel('Özellik Indeksi')\n",
        "    plt.ylabel('Özellik Skoru')\n",
        "    plt.title('Özelliklerin Önem Derecelerinin Dağılımı')\n",
        "    plt.show()\n",
        "\n",
        "# Özelliklerin sıralanmış hali\n",
        "plot_feature_importance(feature_scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "TS3oD1DYWfOg",
        "outputId": "014421bc-97f6-4fee-9ca9-9d1a0b47dd53"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# En iyi 20 özelliğin görselleştirilmesi\n",
        "def plot_top_features(top_features, feature_scores):\n",
        "    \"\"\"\n",
        "    Seçilen en iyi 20 özelliğin önem derecelerini gösteren bar grafiği.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    top_scores = feature_scores[top_features]\n",
        "    plt.bar(range(len(top_features)), top_scores, color='salmon')\n",
        "    plt.xlabel('Özellik Indeksi')\n",
        "    plt.ylabel('Özellik Skoru')\n",
        "    plt.title('En İyi 20 Özelliğin Önem Dereceleri')\n",
        "    plt.show()\n",
        "\n",
        "# Seçilen en iyi 20 özelliği görselleştirme\n",
        "plot_top_features(top_features, feature_scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "eXicC0d_Wi15",
        "outputId": "99d5f844-3137-4b69-9668-f894b4ee5a88"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Özelliklerin sıralanmış halini görselleştirme\n",
        "def plot_sorted_feature_scores(feature_scores):\n",
        "    \"\"\"\n",
        "    Özelliklerin sıralandığı bar grafiği.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sorted_idx = np.argsort(feature_scores)[::-1]\n",
        "    sorted_scores = feature_scores[sorted_idx]\n",
        "    plt.bar(range(len(sorted_scores)), sorted_scores, color='lightgreen')\n",
        "    plt.xlabel('Özellik Indeksi')\n",
        "    plt.ylabel('Özellik Skoru')\n",
        "    plt.title('Özelliklerin Skorlarına Göre Sıralanışı')\n",
        "    plt.show()\n",
        "\n",
        "# Özelliklerin sıralanmış hali\n",
        "plot_sorted_feature_scores(feature_scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "GDrmPn_KWkDI",
        "outputId": "32772fbf-e2af-4430-a4fd-831a41e8bb6c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LGnxkb6yW0oM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filtered_eeg_data'nın yapısını kontrol etme\n",
        "print(filtered_eeg_data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6puX6XNJbRbq",
        "outputId": "ecac9126-8f32-411f-b77a-4b30f67cce62"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q6qi1vNVde8w"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Eğitimi"
      ],
      "metadata": {
        "id": "jbVYs3JGiNoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary Class"
      ],
      "metadata": {
        "id": "oppsCUyviRCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 1. EEG verisini al\n",
        "# filtered_eeg_data, EEG verilerini içeren DataFrame'dir.\n",
        "X = filtered_eeg_data.iloc[:, :14].values  # İlk 14 kanal (eeg.* sütunları)\n",
        "\n",
        "# 2. Hedef verileri (aro ve val)\n",
        "y = filtered_eeg_data[['aro', 'val']].values\n",
        "\n",
        "# 3. Zaman serisi uzunluğunu eşitlemek için en uzun zaman serisini bulma\n",
        "max_length = 0\n",
        "for i in range(X.shape[0]):\n",
        "    for col in range(X.shape[1]):\n",
        "        value = X[i, col]\n",
        "\n",
        "        # Eğer değeri string formatında alıyorsak, listeye dönüştürmek için eval kullanıyoruz\n",
        "        if isinstance(value, str):\n",
        "            time_series = np.array(eval(value))  # String formatındaki array'i alıyoruz\n",
        "        elif isinstance(value, (np.ndarray, list)):\n",
        "            time_series = np.array(value)  # Eğer zaten array veya listse, direkt alıyoruz\n",
        "        else:\n",
        "            raise ValueError(f\"Beklenmeyen veri tipi: {type(value)}\")\n",
        "\n",
        "        # En uzun zaman serisini bulalım\n",
        "        max_length = max(max_length, len(time_series))\n",
        "\n",
        "# 4. Veriyi işleme ve zaman serisi uzunluklarını eşitleme\n",
        "X_processed = []\n",
        "\n",
        "for i in range(X.shape[0]):\n",
        "    processed_data = []\n",
        "    for col in range(X.shape[1]):\n",
        "        value = X[i, col]\n",
        "\n",
        "        if isinstance(value, str):\n",
        "            time_series = np.array(eval(value))  # String formatındaki array'i alıyoruz\n",
        "        elif isinstance(value, (np.ndarray, list)):\n",
        "            time_series = np.array(value)  # Eğer zaten array veya listse, direkt alıyoruz\n",
        "        else:\n",
        "            raise ValueError(f\"Beklenmeyen veri tipi: {type(value)}\")\n",
        "\n",
        "        # Eğer zaman serisinin uzunluğu max_length'ten kısa ise pad edelim\n",
        "        if len(time_series) < max_length:\n",
        "            time_series = np.pad(time_series, (0, max_length - len(time_series)), 'constant')\n",
        "\n",
        "        # İşlenmiş veriyi listeye ekleme\n",
        "        processed_data.append(time_series)\n",
        "\n",
        "    # Tüm kanalları işledikten sonra örneği ekleme\n",
        "    X_processed.append(np.array(processed_data))\n",
        "\n",
        "# 5. Sonuçları numpy array'ine çevirme\n",
        "X_processed = np.array(X_processed)\n",
        "\n",
        "# 6. Şekil kontrolü\n",
        "print(\"X_processed shape:\", X_processed.shape)  # (800, 14, max_length)\n",
        "print(\"y shape:\", y.shape)  # (800, 2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLhua93Pb1fr",
        "outputId": "711bfb76-9875-4a05-f1e7-8cdfa86a1a8e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_processed shape: (800, 14, 5116)\n",
            "y shape: (800, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Eğitim ve test verisi olarak ayırma\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Verilerin şekline göz atma\n",
        "print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8uOuKT5d666",
        "outputId": "6797d9e3-92fa-4303-b047-b638624c5d14"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (640, 14, 5116), X_test shape: (160, 14, 5116)\n",
            "y_train shape: (640, 2), y_test shape: (160, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# MinMaxScaler'i kanal bazında uygulama\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# X_train ve X_test verilerini normalize edelim\n",
        "X_train = X_train.reshape(-1, X_train.shape[-1])  # (800 * 14, max_length)\n",
        "X_test = X_test.reshape(-1, X_test.shape[-1])    # (200 * 14, max_length)\n",
        "\n",
        "# Normalizasyon\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Veriyi eski haline getirelim (reshape to 3D again)\n",
        "X_train_scaled = X_train_scaled.reshape(-1, 14, 5116)\n",
        "X_test_scaled = X_test_scaled.reshape(-1, 14, 5116)\n",
        "\n",
        "print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
        "print(f\"X_test_scaled shape: {X_test_scaled.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhVsjWlWd92i",
        "outputId": "2ba5f32d-51fa-40cd-9d28-c4e18ae9e794"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_scaled shape: (640, 14, 5116)\n",
            "X_test_scaled shape: (160, 14, 5116)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Modeli başlat\n",
        "model = Sequential()\n",
        "\n",
        "# 1. Konvolüsyonel katman (64 filtre, 5x1 kernel)\n",
        "model.add(Conv1D(64, kernel_size=5, activation='relu', input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), padding='same'))\n",
        "model.add(MaxPooling1D(pool_size=2))  # Pooling katmanı\n",
        "\n",
        "# 2. Konvolüsyonel katman (32 filtre, 3x1 kernel)\n",
        "model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "# 3. Konvolüsyonel katman (16 filtre, 3x1 kernel)\n",
        "model.add(Conv1D(16, kernel_size=3, activation='relu', padding='same'))\n",
        "\n",
        "# Flatten katmanı\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dropout katmanı (overfitting'i engellemeye yardımcı olur)\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Tam bağlantı katmanı (Valence ve Arousal için 2 nöron)\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "# Modeli derleyelim\n",
        "optimizer = Adam(learning_rate=0.005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Modelin özetini alalım\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "2WCpzwgIeH1E",
        "outputId": "557cffda-ab19-4be8-c93a-dc170bb1fd9e"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_35 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │       \u001b[38;5;34m1,637,184\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_26 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_36 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │           \u001b[38;5;34m6,176\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_27 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_37 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)               │           \u001b[38;5;34m1,552\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m98\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,637,184</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,645,010\u001b[0m (6.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,645,010</span> (6.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,645,010\u001b[0m (6.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,645,010</span> (6.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model eğitimi\n",
        "history = model.fit(X_train_scaled, y_train, epochs=20, batch_size=64, validation_data=(X_test_scaled, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBOJ--oghA4t",
        "outputId": "f069332c-2c26-4257-9062-91d436f1c2d7"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 235ms/step - accuracy: 0.5337 - loss: 4.6361 - val_accuracy: 0.2500 - val_loss: 0.7976\n",
            "Epoch 2/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - accuracy: 0.6001 - loss: 0.7443 - val_accuracy: 0.7500 - val_loss: 0.7100\n",
            "Epoch 3/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - accuracy: 0.6380 - loss: 0.6869 - val_accuracy: 0.7437 - val_loss: 0.7123\n",
            "Epoch 4/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - accuracy: 0.6336 - loss: 0.6876 - val_accuracy: 0.7500 - val_loss: 0.7072\n",
            "Epoch 5/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 344ms/step - accuracy: 0.6210 - loss: 0.6875 - val_accuracy: 0.7500 - val_loss: 0.7036\n",
            "Epoch 6/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 406ms/step - accuracy: 0.6011 - loss: 0.6885 - val_accuracy: 0.7500 - val_loss: 0.7013\n",
            "Epoch 7/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 202ms/step - accuracy: 0.6178 - loss: 0.6857 - val_accuracy: 0.7500 - val_loss: 0.7016\n",
            "Epoch 8/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - accuracy: 0.6070 - loss: 0.6875 - val_accuracy: 0.7437 - val_loss: 0.6911\n",
            "Epoch 9/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - accuracy: 0.6231 - loss: 0.6889 - val_accuracy: 0.7563 - val_loss: 0.6809\n",
            "Epoch 10/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - accuracy: 0.7574 - loss: 0.6896 - val_accuracy: 0.7500 - val_loss: 0.6918\n",
            "Epoch 11/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 264ms/step - accuracy: 0.7429 - loss: 0.6889 - val_accuracy: 0.7500 - val_loss: 0.6940\n",
            "Epoch 12/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 352ms/step - accuracy: 0.7464 - loss: 0.6887 - val_accuracy: 0.7500 - val_loss: 0.6929\n",
            "Epoch 13/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 205ms/step - accuracy: 0.7272 - loss: 0.6878 - val_accuracy: 0.7500 - val_loss: 0.6919\n",
            "Epoch 14/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - accuracy: 0.7215 - loss: 0.6883 - val_accuracy: 0.7500 - val_loss: 0.6911\n",
            "Epoch 15/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - accuracy: 0.7244 - loss: 0.6880 - val_accuracy: 0.7500 - val_loss: 0.6905\n",
            "Epoch 16/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 276ms/step - accuracy: 0.7459 - loss: 0.6864 - val_accuracy: 0.7500 - val_loss: 0.6899\n",
            "Epoch 17/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 375ms/step - accuracy: 0.7232 - loss: 0.6867 - val_accuracy: 0.7500 - val_loss: 0.6894\n",
            "Epoch 18/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.7316 - loss: 0.6875 - val_accuracy: 0.7500 - val_loss: 0.6891\n",
            "Epoch 19/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 214ms/step - accuracy: 0.7204 - loss: 0.6849 - val_accuracy: 0.7500 - val_loss: 0.6887\n",
            "Epoch 20/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - accuracy: 0.7472 - loss: 0.6847 - val_accuracy: 0.7500 - val_loss: 0.6885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelin performansını değerlendirme\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Valence için metrikler\n",
        "valence_train_pred = y_train_pred[:, 0]\n",
        "valence_test_pred = y_test_pred[:, 0]\n",
        "\n",
        "valence_train_true = y_train[:, 0]\n",
        "valence_test_true = y_test[:, 0]\n",
        "\n",
        "# Eğitimdeki Valence sonuçları\n",
        "valence_train_accuracy = np.mean(valence_train_true == np.round(valence_train_pred))\n",
        "valence_train_loss = np.mean(np.abs(valence_train_true - valence_train_pred))\n",
        "\n",
        "# Testteki Valence sonuçları\n",
        "valence_test_accuracy = np.mean(valence_test_true == np.round(valence_test_pred))\n",
        "valence_test_loss = np.mean(np.abs(valence_test_true - valence_test_pred))\n",
        "\n",
        "# Precision, Recall, F1 Score\n",
        "valence_train_precision = precision_score(valence_train_true, np.round(valence_train_pred))\n",
        "valence_train_recall = recall_score(valence_train_true, np.round(valence_train_pred))\n",
        "valence_train_f1 = f1_score(valence_train_true, np.round(valence_train_pred))\n",
        "\n",
        "valence_test_precision = precision_score(valence_test_true, np.round(valence_test_pred))\n",
        "valence_test_recall = recall_score(valence_test_true, np.round(valence_test_pred))\n",
        "valence_test_f1 = f1_score(valence_test_true, np.round(valence_test_pred))\n",
        "\n",
        "# Arousal için metrikler\n",
        "arousal_train_pred = y_train_pred[:, 1]\n",
        "arousal_test_pred = y_test_pred[:, 1]\n",
        "\n",
        "arousal_train_true = y_train[:, 1]\n",
        "arousal_test_true = y_test[:, 1]\n",
        "\n",
        "# Eğitimdeki Arousal sonuçları\n",
        "arousal_train_accuracy = np.mean(arousal_train_true == np.round(arousal_train_pred))\n",
        "arousal_train_loss = np.mean(np.abs(arousal_train_true - arousal_train_pred))\n",
        "\n",
        "# Testteki Arousal sonuçları\n",
        "arousal_test_accuracy = np.mean(arousal_test_true == np.round(arousal_test_pred))\n",
        "arousal_test_loss = np.mean(np.abs(arousal_test_true - arousal_test_pred))\n",
        "\n",
        "# Precision, Recall, F1 Score\n",
        "arousal_train_precision = precision_score(arousal_train_true, np.round(arousal_train_pred))\n",
        "arousal_train_recall = recall_score(arousal_train_true, np.round(arousal_train_pred))\n",
        "arousal_train_f1 = f1_score(arousal_train_true, np.round(arousal_train_pred))\n",
        "\n",
        "arousal_test_precision = precision_score(arousal_test_true, np.round(arousal_test_pred))\n",
        "arousal_test_recall = recall_score(arousal_test_true, np.round(arousal_test_pred))\n",
        "arousal_test_f1 = f1_score(arousal_test_true, np.round(arousal_test_pred))\n",
        "\n",
        "# Sonuçları yazdıralım\n",
        "print(f\"Valence - Train Accuracy: {valence_train_accuracy}\")\n",
        "print(f\"Valence - Train Loss: {valence_train_loss}\")\n",
        "print(f\"Valence - Test Accuracy: {valence_test_accuracy}\")\n",
        "print(f\"Valence - Test Loss: {valence_test_loss}\")\n",
        "print(f\"Valence - Train Precision: {valence_train_precision}\")\n",
        "print(f\"Valence - Train Recall: {valence_train_recall}\")\n",
        "print(f\"Valence - Train F1 Score: {valence_train_f1}\")\n",
        "print(f\"Valence - Test Precision: {valence_test_precision}\")\n",
        "print(f\"Valence - Test Recall: {valence_test_recall}\")\n",
        "print(f\"Valence - Test F1 Score: {valence_test_f1}\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(f\"Arousal - Train Accuracy: {arousal_train_accuracy}\")\n",
        "print(f\"Arousal - Train Loss: {arousal_train_loss}\")\n",
        "print(f\"Arousal - Test Accuracy: {arousal_test_accuracy}\")\n",
        "print(f\"Arousal - Test Loss: {arousal_test_loss}\")\n",
        "print(f\"Arousal - Train Precision: {arousal_train_precision}\")\n",
        "print(f\"Arousal - Train Recall: {arousal_train_recall}\")\n",
        "print(f\"Arousal - Train F1 Score: {arousal_train_f1}\")\n",
        "print(f\"Arousal - Test Precision: {arousal_test_precision}\")\n",
        "print(f\"Arousal - Test Recall: {arousal_test_recall}\")\n",
        "print(f\"Arousal - Test F1 Score: {arousal_test_f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwIlq-hNemqk",
        "outputId": "ad429494-f058-461f-ba60-db7530c191c9"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Valence - Train Accuracy: 0.5890625\n",
            "Valence - Train Loss: 0.4874662322923541\n",
            "Valence - Test Accuracy: 0.59375\n",
            "Valence - Test Loss: 0.48871956588700416\n",
            "Valence - Train Precision: 0.5890625\n",
            "Valence - Train Recall: 1.0\n",
            "Valence - Train F1 Score: 0.7413962635201573\n",
            "Valence - Test Precision: 0.5974842767295597\n",
            "Valence - Test Recall: 0.9895833333333334\n",
            "Valence - Test F1 Score: 0.7450980392156863\n",
            "\n",
            "\n",
            "Arousal - Train Accuracy: 0.525\n",
            "Arousal - Train Loss: 0.49882282316684723\n",
            "Arousal - Test Accuracy: 0.55625\n",
            "Arousal - Test Loss: 0.49865400455892084\n",
            "Arousal - Train Precision: 0.525\n",
            "Arousal - Train Recall: 1.0\n",
            "Arousal - Train F1 Score: 0.6885245901639344\n",
            "Arousal - Test Precision: 0.559748427672956\n",
            "Arousal - Test Recall: 0.9888888888888889\n",
            "Arousal - Test F1 Score: 0.714859437751004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiclass Model"
      ],
      "metadata": {
        "id": "F7mebDDvh8wR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "80EcqT3XoZBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EEG verilerini (sadece EEG sütunlarını) al\n",
        "eeg_columns = [col for col in filtered_eeg_data.columns if col.startswith('EEG')]\n",
        "\n",
        "# EEG verilerini ve sınıf hedeflerini ayır\n",
        "X = filtered_eeg_data[eeg_columns].values  # Girdi verisi (EEG verileri)\n",
        "y = filtered_eeg_data[['aro_class', 'val_class']].values  # Hedef sınıflar (aro_class ve val_class)\n",
        "\n",
        "# Veriyi eğitim ve test setlerine ayır\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "rZMT4PWmpA4q"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EEG verilerini alıyoruz, sadece \"EEG.\" ile başlayan sütunları seçiyoruz\n",
        "eeg_columns = [col for col in filtered_eeg_data.columns if col.startswith('EEG.')]\n",
        "\n",
        "# EEG verilerinin her bir kanalındaki verilerin uzunluğunu kontrol edelim\n",
        "for column in eeg_columns:\n",
        "    eeg_data_column = filtered_eeg_data[column]\n",
        "    lengths = [len(val) if isinstance(val, list) else 1 for val in eeg_data_column]\n",
        "    print(f\"{column} - Ortalama Uzunluk: {np.mean(lengths)} | Min Uzunluk: {np.min(lengths)} | Max Uzunluk: {np.max(lengths)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVDzs-fxvcUQ",
        "outputId": "dbd63c2f-1ddf-4c51-843c-cd0424f18b85"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EEG.AF3 - Ortalama Uzunluk: 1.0 | Min Uzunluk: 1 | Max Uzunluk: 1\n",
            "EEG.F7 - Ortalama Uzunluk: 1.0 | Min Uzunluk: 1 | Max Uzunluk: 1\n",
            "EEG.F3 - Ortalama Uzunluk: 1.0 | Min Uzunluk: 1 | Max Uzunluk: 1\n",
            "EEG.FC5 - Ortalama Uzunluk: 1.0 | Min Uzunluk: 1 | Max Uzunluk: 1\n",
            "EEG.T7 - Ortalama Uzunluk: 1.0 | Min Uzunluk: 1 | Max Uzunluk: 1\n",
            "EEG.P7 - Ortalama Uzunluk: 1.0 | Min Uzunluk: 1 | Max Uzunluk: 1\n",
            "EEG.O1 - Ortalama Uzunluk: 1.0 | Min Uzunluk: 1 | Max Uzunluk: 1\n",
            "EEG.O2 - Ortalama Uzunluk: 1.0 | Min Uzunluk: 1 | Max Uzunluk: 1\n",
            "EEG.P8 - Ortalama Uzunluk: 1.0 | Min Uzunluk: 1 | Max Uzunluk: 1\n",
            "EEG.T8 - Ortalama Uzunluk: 1.0 | Min Uzunluk: 1 | Max Uzunluk: 1\n",
            "EEG.FC6 - Ortalama Uzunluk: 1.0 | Min Uzunluk: 1 | Max Uzunluk: 1\n",
            "EEG.F4 - Ortalama Uzunluk: 1.0 | Min Uzunluk: 1 | Max Uzunluk: 1\n",
            "EEG.F8 - Ortalama Uzunluk: 1.0 | Min Uzunluk: 1 | Max Uzunluk: 1\n",
            "EEG.AF4 - Ortalama Uzunluk: 1.0 | Min Uzunluk: 1 | Max Uzunluk: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Veriyi dolduracak olan işlevi yazıyoruz\n",
        "def pad_sequence(val, target_length):\n",
        "    # Eğer veri uzunluğu target_length'ten kısa ise, pad yapıyoruz\n",
        "    if isinstance(val, list):\n",
        "        return val + [0] * (target_length - len(val))  # Pad işlemi\n",
        "    return [0] * target_length  # Eğer veri list değilse, 0 ile dolduruyoruz\n",
        "\n",
        "# Tüm EEG verilerini en uzun veri uzunluğuna kadar pad edelim\n",
        "X = []\n",
        "\n",
        "for column in eeg_columns:\n",
        "    eeg_data_column = filtered_eeg_data[column]\n",
        "\n",
        "    # Verileri pad edip düzleştiriyoruz\n",
        "    padded_column_data = np.array([pad_sequence(val, max_length) for val in eeg_data_column])\n",
        "    X.append(padded_column_data)\n",
        "\n",
        "# X'i 2D bir diziye dönüştürüp kontrol edelim\n",
        "X = np.array(X).T  # Verileri transpoze ediyoruz ki her satırda bir EEG kanalının verisi olsun\n",
        "\n",
        "print(f\"Veri boyutu: {X.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4oNpz-XiAea",
        "outputId": "f1043f23-5a88-4944-d73a-15669e80f522"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Veri boyutu: (1, 800, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3D veriyi 2D'ye dönüştürmek: Bu adımda her bir EEG kanalını 2D hale getiriyoruz.\n",
        "X_2d = X.reshape(-1, X.shape[-1])  # 2D'ye çeviriyoruz (tüm örnekler ve tüm kanallar)\n",
        "print(f\"2D veri boyutu: {X_2d.shape}\")\n",
        "\n",
        "# Veriyi normalleştirme\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X_2d)\n",
        "\n",
        "print(f\"Normalleştirilmiş veri boyutu: {X_scaled.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVnmZr9pvzpz",
        "outputId": "4aa779f3-41e5-421e-cfcc-4abd0266afcf"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2D veri boyutu: (800, 14)\n",
            "Normalleştirilmiş veri boyutu: (800, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Hedef değişkeni (örneğin 'val' veya 'aro') belirleyin\n",
        "y = filtered_eeg_data['val']  # Örneğin 'val' hedef değişkeni\n",
        "\n",
        "# Eğitim ve test verisine ayırma\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Eğitim verisi boyutu: {X_train.shape}\")\n",
        "print(f\"Test verisi boyutu: {X_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DL9a0OhwJtc",
        "outputId": "a392bd0b-31b9-4dba-e563-bd82fb824de4"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eğitim verisi boyutu: (640, 14)\n",
            "Test verisi boyutu: (160, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J5PYJs9XwCdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Veriyi normalize etmeden önce özellikleri 1D formatına getirme\n",
        "def pad_sequence(val, target_length):\n",
        "    # Eğer veri uzunluğu target_length'ten kısa ise, pad yapıyoruz\n",
        "    if isinstance(val, list):\n",
        "        return val + [0] * (target_length - len(val))  # Pad işlemi\n",
        "    return [0] * target_length  # Eğer veri list değilse, 0 ile dolduruyoruz\n",
        "\n",
        "# EEG veri boyutlarını belirliyoruz\n",
        "max_length = max([len(val) for val in filtered_eeg_data['EEG.AF3']])  # 'EEG.AF3' örnek olarak alındı, başka bir sütun da olabilir.\n",
        "\n",
        "# Veriyi pad ederek 1D formatına getirme\n",
        "X = []\n",
        "\n",
        "# EEG sütunlarını kullanarak her bir kanalın verisini işleme\n",
        "for column in eeg_columns:\n",
        "    eeg_data_column = filtered_eeg_data[column]  # Filtrelenmiş EEG verisi\n",
        "\n",
        "    # Her bir veriyi pad ediyoruz\n",
        "    padded_column_data = np.array([pad_sequence(val, max_length) for val in eeg_data_column])\n",
        "    X.append(padded_column_data)\n",
        "\n",
        "# X'i 2D bir diziye dönüştürüp kontrol etme\n",
        "X = np.array(X).T  # Her satırda bir EEG kanalının verisi olsun\n",
        "\n",
        "# Normalleştirme\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X.reshape(-1, 1)).reshape(X.shape)  # 1D-CNN için uygun formatta normalleştiriyoruz\n",
        "\n",
        "print(f\"Normalleştirilmiş veri boyutu: {X_scaled.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQIcXvwXwLtn",
        "outputId": "6d922d1c-79f4-4cfe-ca3c-1335aea4a4ec"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalleştirilmiş veri boyutu: (5116, 800, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_scaled'i (örnek sayısı, zaman adımları * kanal sayısı) formatına dönüştür\n",
        "X_scaled_reshaped = X_scaled.reshape(X_scaled.shape[0], -1)\n",
        "\n",
        "# Verilerin boyutlarını kontrol etme\n",
        "print(f\"X_scaled_reshaped shape: {X_scaled_reshaped.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFMxNZuEyvv8",
        "outputId": "906a3e2c-6a97-44c9-c62f-6a88b95a850a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_scaled_reshaped shape: (5116, 11200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y boyutunu kontrol etme\n",
        "print(f\"y shape: {y.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLdO5psiyyyo",
        "outputId": "2e6a4f05-3d2e-4b5f-8582-82ddde836d38"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y shape: (800, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eğitim ve test setlerine ayırmadan önce, örnekleri uyumlu hale getirelim\n",
        "import numpy as np\n",
        "\n",
        "# Verilerdeki örnek sayısını kontrol edelim\n",
        "num_samples = X_scaled.shape[0]\n",
        "target_samples = y.shape[0]\n",
        "\n",
        "# Eğer X'deki örnek sayısı, y'deki örnek sayısına uymuyorsa, uyumlu hale getirelim\n",
        "# Bu durumda X'in örnek sayısını y'nin boyutuna uyarlayacağız\n",
        "X_scaled_resized = X_scaled[:target_samples]\n",
        "\n",
        "# Yeni boyutları kontrol edelim\n",
        "print(f\"Yeni X boyutu: {X_scaled_resized.shape}\")\n",
        "print(f\"Yeni y boyutu: {y.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXhti5_BzGWV",
        "outputId": "361ae8f8-c0fe-4457-c5b1-29f90764b56c"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yeni X boyutu: (800, 800, 14)\n",
            "Yeni y boyutu: (800, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Eğitim ve test setlerine ayıralım\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled_resized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Verilerin boyutlarını kontrol edelim\n",
        "print(f\"X_train boyutu: {X_train.shape}\")\n",
        "print(f\"X_test boyutu: {X_test.shape}\")\n",
        "print(f\"y_train boyutu: {y_train.shape}\")\n",
        "print(f\"y_test boyutu: {y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY-1PYHuyP8c",
        "outputId": "cf5ad6ab-0a4e-4be4-9a91-169210683c21"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train boyutu: (640, 800, 14)\n",
            "X_test boyutu: (160, 800, 14)\n",
            "y_train boyutu: (640, 2)\n",
            "y_test boyutu: (160, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Modeli oluşturma\n",
        "model = models.Sequential()\n",
        "\n",
        "# İlk 1D Conv katmanı\n",
        "model.add(layers.Conv1D(64, 5, activation='relu', input_shape=(800, 14)))  # (zaman_adımı, kanal_sayısı)\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling1D(2))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "# İkinci 1D Conv katmanı\n",
        "model.add(layers.Conv1D(32, 5, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling1D(2))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "# Üçüncü 1D Conv katmanı\n",
        "model.add(layers.Conv1D(16, 3, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling1D(2))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "# Veriyi düzleştirme (flatten)\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Tam bağlantılı katman\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "# Çıktı katmanı - valence ve arousal için 2 ayrı çıktı\n",
        "model.add(layers.Dense(2, activation='sigmoid'))  # Çift sınıflı çıktı (valence ve arousal)\n",
        "\n",
        "# Modelin derlenmesi\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Modelin özeti\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "id": "7XGEnFuTyGSG",
        "outputId": "c82c37e8-6900-4637-8ec9-d1edff4ad508"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m796\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m4,544\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m796\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_7 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m398\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m398\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m394\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │          \u001b[38;5;34m10,272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m394\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_8 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m197\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m197\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m1,552\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │              \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_9 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m16\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m16\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1552\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m99,392\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m130\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">796</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,544</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">796</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">398</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">398</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">394</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">394</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">197</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">197</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1552</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">99,392</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m116,338\u001b[0m (454.45 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">116,338</span> (454.45 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m116,114\u001b[0m (453.57 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">116,114</span> (453.57 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modeli eğitiyoruz\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqDStw3LzWFp",
        "outputId": "e7ba2be5-84bb-4283-b70b-cfae9bba613b"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - accuracy: 0.3386 - loss: 0.6875 - val_accuracy: 0.2812 - val_loss: 0.6860\n",
            "Epoch 2/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - accuracy: 0.3323 - loss: 0.6856 - val_accuracy: 0.2812 - val_loss: 0.6855\n",
            "Epoch 3/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.3045 - loss: 0.6858 - val_accuracy: 0.2812 - val_loss: 0.6852\n",
            "Epoch 4/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 151ms/step - accuracy: 0.3116 - loss: 0.6883 - val_accuracy: 0.2812 - val_loss: 0.6850\n",
            "Epoch 5/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 175ms/step - accuracy: 0.3174 - loss: 0.6878 - val_accuracy: 0.2812 - val_loss: 0.6846\n",
            "Epoch 6/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 204ms/step - accuracy: 0.3286 - loss: 0.6859 - val_accuracy: 0.2812 - val_loss: 0.6843\n",
            "Epoch 7/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - accuracy: 0.3081 - loss: 0.6867 - val_accuracy: 0.2812 - val_loss: 0.6840\n",
            "Epoch 8/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.3315 - loss: 0.6853 - val_accuracy: 0.2812 - val_loss: 0.6838\n",
            "Epoch 9/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 202ms/step - accuracy: 0.3363 - loss: 0.6865 - val_accuracy: 0.2812 - val_loss: 0.6836\n",
            "Epoch 10/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.3279 - loss: 0.6849 - val_accuracy: 0.2812 - val_loss: 0.6834\n",
            "Epoch 11/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.3485 - loss: 0.6867 - val_accuracy: 0.2812 - val_loss: 0.6832\n",
            "Epoch 12/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.3336 - loss: 0.6855 - val_accuracy: 0.2812 - val_loss: 0.6830\n",
            "Epoch 13/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.2996 - loss: 0.6862 - val_accuracy: 0.2812 - val_loss: 0.6829\n",
            "Epoch 14/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 172ms/step - accuracy: 0.3167 - loss: 0.6880 - val_accuracy: 0.2812 - val_loss: 0.6827\n",
            "Epoch 15/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.3261 - loss: 0.6879 - val_accuracy: 0.2812 - val_loss: 0.6826\n",
            "Epoch 16/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.3251 - loss: 0.6848 - val_accuracy: 0.2812 - val_loss: 0.6824\n",
            "Epoch 17/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.3234 - loss: 0.6839 - val_accuracy: 0.2812 - val_loss: 0.6823\n",
            "Epoch 18/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.3111 - loss: 0.6838 - val_accuracy: 0.2812 - val_loss: 0.6822\n",
            "Epoch 19/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - accuracy: 0.3412 - loss: 0.6841 - val_accuracy: 0.2812 - val_loss: 0.6821\n",
            "Epoch 20/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 203ms/step - accuracy: 0.3319 - loss: 0.6851 - val_accuracy: 0.2812 - val_loss: 0.6820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tm_vb9AkwiN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IpvAlzBRwiKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Model tahminleri\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Valence ve Arousal tahminlerini kategorik hale getirme (eşik = 0.5)\n",
        "valence_train_pred = np.round(y_train_pred[:, 0])\n",
        "valence_test_pred = np.round(y_test_pred[:, 0])\n",
        "valence_train_true = y_train[:, 0]\n",
        "valence_test_true = y_test[:, 0]\n",
        "\n",
        "arousal_train_pred = np.round(y_train_pred[:, 1])\n",
        "arousal_test_pred = np.round(y_test_pred[:, 1])\n",
        "arousal_train_true = y_train[:, 1]\n",
        "arousal_test_true = y_test[:, 1]\n",
        "\n",
        "# Valence metrikleri\n",
        "valence_train_accuracy = accuracy_score(valence_train_true, valence_train_pred)\n",
        "valence_test_accuracy = accuracy_score(valence_test_true, valence_test_pred)\n",
        "valence_train_precision = precision_score(valence_train_true, valence_train_pred)\n",
        "valence_train_recall = recall_score(valence_train_true, valence_train_pred)\n",
        "valence_train_f1 = f1_score(valence_train_true, valence_train_pred)\n",
        "valence_test_precision = precision_score(valence_test_true, valence_test_pred)\n",
        "valence_test_recall = recall_score(valence_test_true, valence_test_pred)\n",
        "valence_test_f1 = f1_score(valence_test_true, valence_test_pred)\n",
        "\n",
        "# Arousal metrikleri\n",
        "arousal_train_accuracy = accuracy_score(arousal_train_true, arousal_train_pred)\n",
        "arousal_test_accuracy = accuracy_score(arousal_test_true, arousal_test_pred)\n",
        "arousal_train_precision = precision_score(arousal_train_true, arousal_train_pred)\n",
        "arousal_train_recall = recall_score(arousal_train_true, arousal_train_pred)\n",
        "arousal_train_f1 = f1_score(arousal_train_true, arousal_train_pred)\n",
        "arousal_test_precision = precision_score(arousal_test_true, arousal_test_pred)\n",
        "arousal_test_recall = recall_score(arousal_test_true, arousal_test_pred)\n",
        "arousal_test_f1 = f1_score(arousal_test_true, arousal_test_pred)\n",
        "\n",
        "# Sonuçları yazdırma\n",
        "print(f\"Valence - Train Accuracy: {valence_train_accuracy}\")\n",
        "print(f\"Valence - Train Loss: {np.mean(np.abs(valence_train_true - valence_train_pred))}\")\n",
        "print(f\"Valence - Test Accuracy: {valence_test_accuracy}\")\n",
        "print(f\"Valence - Test Loss: {np.mean(np.abs(valence_test_true - valence_test_pred))}\")\n",
        "print(f\"Valence - Train Precision: {valence_train_precision}\")\n",
        "print(f\"Valence - Train Recall: {valence_train_recall}\")\n",
        "print(f\"Valence - Train F1 Score: {valence_train_f1}\")\n",
        "print(f\"Valence - Test Precision: {valence_test_precision}\")\n",
        "print(f\"Valence - Test Recall: {valence_test_recall}\")\n",
        "print(f\"Valence - Test F1 Score: {valence_test_f1}\")\n",
        "print(\"\\n\")\n",
        "print(f\"Arousal - Train Accuracy: {arousal_train_accuracy}\")\n",
        "print(f\"Arousal - Train Loss: {np.mean(np.abs(arousal_train_true - arousal_train_pred))}\")\n",
        "print(f\"Arousal - Test Accuracy: {arousal_test_accuracy}\")\n",
        "print(f\"Arousal - Test Loss: {np.mean(np.abs(arousal_test_true - arousal_test_pred))}\")\n",
        "print(f\"Arousal - Train Precision: {arousal_train_precision}\")\n",
        "print(f\"Arousal - Train Recall: {arousal_train_recall}\")\n",
        "print(f\"Arousal - Train F1 Score: {arousal_train_f1}\")\n",
        "print(f\"Arousal - Test Precision: {arousal_test_precision}\")\n",
        "print(f\"Arousal - Test Recall: {arousal_test_recall}\")\n",
        "print(f\"Arousal - Test F1 Score: {arousal_test_f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEQP_96UmurK",
        "outputId": "59189fc8-5927-4524-9f2a-d16d0725d1b1"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Valence - Train Accuracy: 0.525\n",
            "Valence - Train Loss: 0.475\n",
            "Valence - Test Accuracy: 0.5625\n",
            "Valence - Test Loss: 0.4375\n",
            "Valence - Train Precision: 0.525\n",
            "Valence - Train Recall: 1.0\n",
            "Valence - Train F1 Score: 0.6885245901639344\n",
            "Valence - Test Precision: 0.5625\n",
            "Valence - Test Recall: 1.0\n",
            "Valence - Test F1 Score: 0.72\n",
            "\n",
            "\n",
            "Arousal - Train Accuracy: 0.5890625\n",
            "Arousal - Train Loss: 0.4109375\n",
            "Arousal - Test Accuracy: 0.6\n",
            "Arousal - Test Loss: 0.4\n",
            "Arousal - Train Precision: 0.5890625\n",
            "Arousal - Train Recall: 1.0\n",
            "Arousal - Train F1 Score: 0.7413962635201573\n",
            "Arousal - Test Precision: 0.6\n",
            "Arousal - Test Recall: 1.0\n",
            "Arousal - Test F1 Score: 0.75\n"
          ]
        }
      ]
    }
  ]
}